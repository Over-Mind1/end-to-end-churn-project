{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09703e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import os\n",
    "import optuna\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0faada",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(),\"..\", \"data\", \"raw\", \"churn-data.csv\")\n",
    "df=pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c3ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48b0b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1ccb1",
   "metadata": {},
   "source": [
    "# feature engineering based on previous analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581d21d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   CreditScore            10000 non-null  int64  \n",
      " 1   Geography              10000 non-null  object \n",
      " 2   Gender                 10000 non-null  object \n",
      " 3   Age                    10000 non-null  int64  \n",
      " 4   Tenure                 10000 non-null  int64  \n",
      " 5   Balance                10000 non-null  float64\n",
      " 6   NumOfProducts          10000 non-null  int64  \n",
      " 7   HasCrCard              10000 non-null  int64  \n",
      " 8   IsActiveMember         10000 non-null  int64  \n",
      " 9   EstimatedSalary        10000 non-null  float64\n",
      " 10  Exited                 10000 non-null  int64  \n",
      " 11  IsZeroBalance          10000 non-null  int64  \n",
      " 12  AgeGroup               10000 non-null  object \n",
      " 13  CreditTier             10000 non-null  object \n",
      " 14  CustomerValue          10000 non-null  float64\n",
      " 15  AgeProduct             10000 non-null  float64\n",
      " 16  ActivityScore          10000 non-null  int64  \n",
      " 17  LogBalanceSalaryRatio  10000 non-null  float64\n",
      " 18  HighBalance            10000 non-null  int64  \n",
      " 19  CLV                    10000 non-null  float64\n",
      "dtypes: float64(6), int64(10), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "class FeatureEngineering:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    # Age groups mapping\n",
    "    def age_group(self, age):\n",
    "        if age < 30:\n",
    "            return \"Young\"\n",
    "        elif age < 45:\n",
    "            return \"Adult\"\n",
    "        elif age < 60:\n",
    "            return \"Senior\"\n",
    "        else:\n",
    "            return \"Elderly\"\n",
    "    # Credit score tiers mapping based on VantageScore\n",
    "    def credit_score_tier(self,score):\n",
    "        if score >= 781:\n",
    "            return \"superprime\"\n",
    "        elif score >= 661:\n",
    "            return \"prime\"\n",
    "        elif score >= 601:\n",
    "            return \"near prime\"\n",
    "        elif score >= 300:\n",
    "            return \"subprime\"\n",
    "        else:\n",
    "            return \"Very Poor\"\n",
    "    def make_feature_extraction(self):\n",
    "        df = self.df.copy()\n",
    "\n",
    "        # -------------------------\n",
    "        # 1. Zero balance indicator\n",
    "        # -------------------------\n",
    "        df[\"IsZeroBalance\"] = (df[\"Balance\"] == 0).astype(int)\n",
    "\n",
    "        # -------------------------\n",
    "        # 2. Age groups\n",
    "        # -------------------------\n",
    "        df[\"AgeGroup\"] = df[\"Age\"].apply(self.age_group)\n",
    "\n",
    "        # -------------------------\n",
    "        # 3. Credit score tiers VantageScore Credit Score\n",
    "        # -------------------------\n",
    "\n",
    "        df[\"CreditTier\"] = df[\"CreditScore\"].apply(self.credit_score_tier)\n",
    "\n",
    "        # -------------------------\n",
    "        # 4. Customer Value (improved)\n",
    "        # Balance + Salary is better indicator\n",
    "        # -------------------------\n",
    "        df[\"CustomerValue\"] = df[\"Balance\"] + df[\"EstimatedSalary\"]\n",
    "\n",
    "        # -------------------------\n",
    "        # 5. Age Ã— NumOfProducts\n",
    "        # -------------------------\n",
    "        df[\"AgeProduct\"] = np.log1p(df[\"Age\"] * df[\"NumOfProducts\"])\n",
    "\n",
    "        # -------------------------\n",
    "        # 6. Activity Score \n",
    "        # -------------------------\n",
    "        df[\"ActivityScore\"] = df[\"IsActiveMember\"] * df[\"NumOfProducts\"]\n",
    "\n",
    "        # -------------------------\n",
    "        # 7. Log Balance/Salary Ratio (BEST version)\n",
    "        # More stable, avoids skew\n",
    "        # -------------------------\n",
    "        df[\"LogBalanceSalaryRatio\"] = (\n",
    "            np.log1p(df[\"Balance\"]) - np.log1p(df[\"EstimatedSalary\"])\n",
    "        )\n",
    "\n",
    "        # -------------------------\n",
    "        # 8. High balance flag\n",
    "        # -------------------------\n",
    "        df[\"HighBalance\"] = (df[\"Balance\"] > df[\"Balance\"].median()).astype(int)\n",
    "\n",
    "        # -------------------------\n",
    "        # 9. Customer Lifetime Value (CLV)\n",
    "        # -------------------------\n",
    "        df[\"CLV\"] = df[\"Tenure\"] * df[\"Balance\"]\n",
    "\n",
    "        return df\n",
    "fe = FeatureEngineering(df)\n",
    "df_new_features = fe.make_feature_extraction()\n",
    "df_new_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48953361",
   "metadata": {},
   "source": [
    "# split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69f50c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features.to_csv(os.path.join(os.getcwd(),\"..\", \"data\", \"processed\", \"churn-data-features.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f64ea43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (10000, 20)\n",
      "X_train shape: (8000, 19)\n",
      "X_test shape: (2000, 19)\n",
      "y_train shape: (8000,)\n",
      "y_test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "X = df_new_features.drop('Exited', axis=1)\n",
    "y = df_new_features['Exited']\n",
    "\n",
    "#split the data into training and testing sets with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "# check shape of the splits\n",
    "print(\"df shape:\", df_new_features.shape)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "730b7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature categories\n",
    "numerical_features = ['CreditScore', 'Tenure','Age', 'Balance', 'EstimatedSalary','LogBalanceSalaryRatio','CustomerValue','AgeProduct','CLV']\n",
    "categorical_features=['Geography', 'Gender','AgeGroup', 'CreditTier']\n",
    "ready_cols = list(set(X_train.columns.tolist()) - set(numerical_features) - set(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e876b3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>LogBalanceSalaryRatio</th>\n",
       "      <th>CustomerValue</th>\n",
       "      <th>AgeProduct</th>\n",
       "      <th>CLV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>753</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>159475.08</td>\n",
       "      <td>-11.979649</td>\n",
       "      <td>159475.08</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8392</th>\n",
       "      <td>739</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>102128.27</td>\n",
       "      <td>63981.37</td>\n",
       "      <td>0.467632</td>\n",
       "      <td>166109.64</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>306384.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>755</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>113865.23</td>\n",
       "      <td>117396.25</td>\n",
       "      <td>-0.030539</td>\n",
       "      <td>231261.48</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>561</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83093.25</td>\n",
       "      <td>-11.327731</td>\n",
       "      <td>83093.25</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7182</th>\n",
       "      <td>692</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>110540.43</td>\n",
       "      <td>107472.99</td>\n",
       "      <td>0.028142</td>\n",
       "      <td>218013.42</td>\n",
       "      <td>4.595120</td>\n",
       "      <td>663242.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Tenure  Age    Balance  EstimatedSalary  \\\n",
       "2151          753       7   57       0.00        159475.08   \n",
       "8392          739       3   32  102128.27         63981.37   \n",
       "5006          755       0   37  113865.23        117396.25   \n",
       "4117          561       5   37       0.00         83093.25   \n",
       "7182          692       6   49  110540.43        107472.99   \n",
       "\n",
       "      LogBalanceSalaryRatio  CustomerValue  AgeProduct        CLV  \n",
       "2151             -11.979649      159475.08    4.060443       0.00  \n",
       "8392               0.467632      166109.64    3.496508  306384.81  \n",
       "5006              -0.030539      231261.48    4.317488       0.00  \n",
       "4117             -11.327731       83093.25    4.317488       0.00  \n",
       "7182               0.028142      218013.42    4.595120  663242.58  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[numerical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0e849d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns.tolist()) == len(ready_cols)+len(numerical_features)+len(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f376db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of numerical features:\n",
      " Age                      1.035706\n",
      "CLV                      0.877814\n",
      "AgeProduct               0.259080\n",
      "Tenure                   0.013124\n",
      "EstimatedSalary          0.007126\n",
      "CustomerValue           -0.074331\n",
      "CreditScore             -0.079540\n",
      "Balance                 -0.141721\n",
      "LogBalanceSalaryRatio   -0.538151\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check skewness of numerical features\n",
    "skewed_feats = X_train[numerical_features].skew().sort_values(ascending=False)\n",
    "print(\"Skewness of numerical features:\\n\", skewed_feats)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90796bc0",
   "metadata": {},
   "source": [
    "# pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9facacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for non skewed numerical features\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "\n",
    "\n",
    "#for categorical features\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',sparse_output=False, drop='first'))\n",
    "])\n",
    "\n",
    "\n",
    "#for ready to use features\n",
    "ready_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Combine all pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, numerical_features),\n",
    "        ('cat', cat_pipeline, categorical_features),\n",
    "        ('ready', ready_pipeline, ready_cols)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6599bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed X_train shape: (8000, 24)\n",
      "Processed X_test shape: (2000, 24)\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------\n",
    "# add noise features to test preprocessing robustness\n",
    "#---------------------------------------------------------\n",
    "\n",
    "# num_noise_features = 1\n",
    "# for i in range(num_noise_features):\n",
    "#     noise_feature_name = f'NoiseFeature_{i+1}'\n",
    "#     X_train[noise_feature_name] = np.random.rand(X_train.shape[0])\n",
    "#     X_test[noise_feature_name] = np.random.rand(X_test.shape[0])\n",
    "#     ready_cols.append(noise_feature_name)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# Fit and transform the training data\n",
    "#---------------------------------------------------------\n",
    "X_train_processed = preprocessor.fit_transform(X_train) \n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "print(\"Processed X_train shape:\", X_train_processed.shape)\n",
    "print(\"Processed X_test shape:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accf1ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(0.6279434850863422), 1: np.float64(2.4539877300613497)}\n"
     ]
    }
   ],
   "source": [
    "#compute class weights to handle class imbalance\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i : class_weights[i] for i in range(len(class_weights))}\n",
    "print(\"Class weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36699ac6",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750d8ae",
   "metadata": {},
   "source": [
    "# baseline xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cec9ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      1593\n",
      "           1       0.59      0.60      0.60       407\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.75      0.75      0.75      2000\n",
      "weighted avg       0.84      0.83      0.84      2000\n",
      "\n",
      "f1  0.5955882352941176\n",
      "===========================================================\n",
      "Classification Report for Training Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      6370\n",
      "           1       0.87      0.99      0.93      1630\n",
      "\n",
      "    accuracy                           0.97      8000\n",
      "   macro avg       0.93      0.98      0.95      8000\n",
      "weighted avg       0.97      0.97      0.97      8000\n",
      "\n",
      "f1  0.925236321970782\n"
     ]
    }
   ],
   "source": [
    "# xgboost model with smote\n",
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=class_weights_dict[1]/class_weights_dict[0], random_state=42)\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_processed)\n",
    "print(\"Classification Report for Test Set:\\n\", classification_report(y_test, y_test_pred_xgb))\n",
    "print('f1 ', f1_score(y_test, y_test_pred_xgb))\n",
    "print('===========================================================')\n",
    "y_train_pred_xgb = xgb_model.predict(X_train_processed)\n",
    "print(\"Classification Report for Training Set:\\n\", classification_report(y_train, y_train_pred_xgb))\n",
    "print('f1 ', f1_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012bee90",
   "metadata": {},
   "source": [
    "#  XGBoost hyperparameters tunning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fbfe0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    # XGBoost hyperparameters\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 42,\n",
    "        # Class imbalance handling\n",
    "        \"scale_pos_weight\": class_weights_dict[1] / class_weights_dict[0],\n",
    "\n",
    "        # Trial suggestions\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10)\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train_processed, y_train)\n",
    "\n",
    "    preds = model.predict(X_test_processed)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1a305d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 Score: 0.6338185890257558\n",
      "Best Hyperparameters: {'n_estimators': 279, 'max_depth': 9, 'learning_rate': 0.04539013027168558, 'subsample': 0.739458666139444, 'colsample_bytree': 0.7848215837184851, 'gamma': 3.3877904103418386, 'min_child_weight': 2}\n"
     ]
    }
   ],
   "source": [
    "# Create and run study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(xgb_objective, n_trials=200, show_progress_bar=False)\n",
    "# Best results\n",
    "print(\"Best F1 Score:\", study.best_value)\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "xgb_best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b59cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1593\n",
      "           1       0.76      0.50      0.60       407\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.82      0.73      0.76      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n",
      "f1  0.6044444444444445\n",
      "===========================================================\n",
      "Classification Report for Training Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      6370\n",
      "           1       0.86      0.57      0.68      1630\n",
      "\n",
      "    accuracy                           0.89      8000\n",
      "   macro avg       0.88      0.77      0.81      8000\n",
      "weighted avg       0.89      0.89      0.88      8000\n",
      "\n",
      "f1  0.6834319526627219\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(**xgb_best_params,random_state=42)\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_processed)\n",
    "print(\"Classification Report for Test Set:\\n\", classification_report(y_test, y_test_pred_xgb))\n",
    "print('f1 ', f1_score(y_test, y_test_pred_xgb))\n",
    "print('===========================================================')\n",
    "y_train_pred_xgb = xgb_model.predict(X_train_processed)\n",
    "print(\"Classification Report for Training Set:\\n\", classification_report(y_train, y_train_pred_xgb))\n",
    "print('f1 ', f1_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922df054",
   "metadata": {},
   "source": [
    "# SHAP feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fcb022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=preprocessor.get_feature_names_out().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7301dd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 7995/8000 [00:23<00:00]        "
     ]
    }
   ],
   "source": [
    "explainer = shap.Explainer(xgb_model, X_train_processed)\n",
    "shap_values = explainer(X_train_processed)\n",
    "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "# Create DF\n",
    "shap_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'SHAP_Value': mean_abs_shap\n",
    "}).sort_values(by='SHAP_Value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c40d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ready__NumOfProducts', 'num__Age', 'ready__ActivityScore', 'cat__Gender_Male', 'num__AgeProduct', 'cat__Geography_Germany', 'num__LogBalanceSalaryRatio', 'num__Balance', 'cat__AgeGroup_Senior', 'ready__IsActiveMember']\n"
     ]
    }
   ],
   "source": [
    "shap_df_xgb = shap_df.copy()\n",
    "shap_df_xgb['cumsum'] = shap_df_xgb['SHAP_Value'].cumsum()\n",
    "shap_df_xgb['cumsum_percent'] = 100 * shap_df_xgb['cumsum'] / shap_df_xgb['SHAP_Value'].sum()\n",
    "\n",
    "top_features = shap_df_xgb[shap_df_xgb['cumsum_percent'] <= 90]['Feature'].tolist()\n",
    "print(top_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85ffe5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          ready__NumOfProducts\n",
       "1                      num__Age\n",
       "2          ready__ActivityScore\n",
       "3              cat__Gender_Male\n",
       "4               num__AgeProduct\n",
       "5        cat__Geography_Germany\n",
       "6    num__LogBalanceSalaryRatio\n",
       "7                  num__Balance\n",
       "8          cat__AgeGroup_Senior\n",
       "9         ready__IsActiveMember\n",
       "Name: Feature, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_df_xgb['Feature'][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c3271c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = shap_df_xgb['Feature'][:10].tolist()\n",
    "top_feature_indices = [feature_names.index(feat) for feat in top_features]\n",
    "X_train_top = X_train_processed[:, top_feature_indices]\n",
    "X_test_top = X_test_processed[:, top_feature_indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b9e41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      1593\n",
      "           1       0.78      0.48      0.59       407\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.83      0.72      0.76      2000\n",
      "weighted avg       0.86      0.87      0.85      2000\n",
      "\n",
      "f1  0.5914634146341463\n",
      "Classification Report for train:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      6370\n",
      "           1       0.81      0.51      0.63      1630\n",
      "\n",
      "    accuracy                           0.88      8000\n",
      "   macro avg       0.85      0.74      0.78      8000\n",
      "weighted avg       0.87      0.88      0.87      8000\n",
      "\n",
      "f1  0.6278195488721805\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "# xgboost model with class weights\n",
    "final_xgb_model = xgb.XGBClassifier(**xgb_best_params)\n",
    "final_xgb_model.fit(X_train_top, y_train)\n",
    "y_test_pred_xgb = final_xgb_model.predict(X_test_top)\n",
    "print(\"Classification Report for test:\\n\", classification_report(y_test, y_test_pred_xgb))    \n",
    "print('f1 ', f1_score(y_test, y_test_pred_xgb))\n",
    "y_train_pred_xgb = final_xgb_model.predict(X_train_top)\n",
    "print(\"Classification Report for train:\\n\", classification_report(y_train, y_train_pred_xgb))\n",
    "print('f1 ', f1_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2d68c",
   "metadata": {},
   "source": [
    "# threshold tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70e205ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.32999999999999985 Best F1: 0.6525529265255293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probs = final_xgb_model.predict_proba(X_test_top)[:,1]\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for thresh in np.arange(0.1, 0.9, 0.01):\n",
    "    preds = (probs > thresh).astype(int)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(\"Best threshold:\", best_thresh, \"Best F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef5d3e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1593\n",
      "           1       0.66      0.64      0.65       407\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.79      0.78      0.78      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "f1  0.6525529265255293\n",
      "===========================================================\n",
      "Classification Report for train:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      6370\n",
      "           1       0.68      0.67      0.67      1630\n",
      "\n",
      "    accuracy                           0.87      8000\n",
      "   macro avg       0.80      0.79      0.80      8000\n",
      "weighted avg       0.87      0.87      0.87      8000\n",
      "\n",
      "f1  0.6747286821705426\n"
     ]
    }
   ],
   "source": [
    "probs = final_xgb_model.predict_proba(X_test_top)[:, 1]\n",
    "y_test_pred_xgb = (probs > best_thresh).astype(int)\n",
    "print(\"Classification Report for test:\\n\", classification_report(y_test, y_test_pred_xgb))    \n",
    "print('f1 ', f1_score(y_test, y_test_pred_xgb))\n",
    "print('===========================================================')\n",
    "y_train_pred_xgb = (final_xgb_model.predict_proba(X_train_top)[:, 1] > best_thresh).astype(int)\n",
    "print(\"Classification Report for train:\\n\", classification_report(y_train, y_train_pred_xgb))\n",
    "print('f1 ', f1_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a266d",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465e378e",
   "metadata": {},
   "source": [
    "# catboost model base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9226a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      1593\n",
      "           1       0.80      0.49      0.61       407\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.84      0.73      0.77      2000\n",
      "weighted avg       0.87      0.87      0.86      2000\n",
      "\n",
      "f1 score for test 0.6118721461187214\n",
      "=====================================================\n",
      "Classification Report for train:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      6370\n",
      "           1       0.91      0.64      0.75      1630\n",
      "\n",
      "    accuracy                           0.91      8000\n",
      "   macro avg       0.91      0.81      0.85      8000\n",
      "weighted avg       0.91      0.91      0.91      8000\n",
      "\n",
      "f1 score for train 0.7496402877697842\n"
     ]
    }
   ],
   "source": [
    "cat_model = CatBoostClassifier(verbose=False,random_seed=42)\n",
    "train_pool = Pool(X_train_processed, y_train)\n",
    "cat_model.fit(train_pool)\n",
    "\n",
    "y_test_pred_cat = cat_model.predict(X_test_processed)\n",
    "print(\"Classification Report for test:\\n\", classification_report(y_test, y_test_pred_cat)) \n",
    "print('f1 score for test',f1_score(y_test, y_test_pred_cat))\n",
    "print('=====================================================')\n",
    "y_train_pred_cat = cat_model.predict(X_train_processed)\n",
    "print(\"Classification Report for train:\\n\", classification_report(y_train, y_train_pred_cat))\n",
    "print('f1 score for train',f1_score(y_train, y_train_pred_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bbf8bb",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning for catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "05376d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 200, 1200),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 10.0),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 10.0),\n",
    "\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.8, 5.0),\n",
    "\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"F1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "        \"random_seed\": 42,\n",
    "        \"use_best_model\": False\n",
    "    }\n",
    "\n",
    "    # Pool\n",
    "    train_pool = Pool(X_train_processed, y_train)\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        early_stopping_rounds=70,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Predict on validation\n",
    "    preds = model.predict(X_test_processed)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52691445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Best F1: 0.6523388116308471\n",
      "ðŸ”¥ Best Params:\n",
      " {'iterations': 265, 'depth': 4, 'learning_rate': 0.06529304400269391, 'l2_leaf_reg': 5.67095569918552, 'bagging_temperature': 0.6898766159711811, 'random_strength': 2.723472757442978, 'scale_pos_weight': 1.9383098788024475}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(cat_objective, n_trials=120)\n",
    "\n",
    "print(\"\\n Best F1:\", study.best_value)\n",
    "print(\" Best Params:\\n\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e02ad743",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_best_params = study.best_params\n",
    "cat_best_params[\"loss_function\"] = \"Logloss\"\n",
    "cat_best_params[\"eval_metric\"] = \"F1\"\n",
    "cat_best_params[\"verbose\"] = False\n",
    "cat_best_params[\"use_best_model\"] = False\n",
    "cat_best_params[\"random_seed\"] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c78165b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1593\n",
      "           1       0.67      0.63      0.65       407\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.79      0.78      0.78      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "F1: 0.6523388116308471\n",
      "===================================================\n",
      "\n",
      "Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      6370\n",
      "           1       0.70      0.65      0.68      1630\n",
      "\n",
      "    accuracy                           0.87      8000\n",
      "   macro avg       0.81      0.79      0.80      8000\n",
      "weighted avg       0.87      0.87      0.87      8000\n",
      "\n",
      "F1: 0.6755386565272496\n"
     ]
    }
   ],
   "source": [
    "tunned_cat_model = CatBoostClassifier(**cat_best_params)\n",
    "\n",
    "train_pool = Pool(X_train_processed, y_train)\n",
    "valid_pool = Pool(X_test_processed, y_test)\n",
    "\n",
    "tunned_cat_model.fit(\n",
    "    train_pool,\n",
    "    eval_set=valid_pool,\n",
    "    early_stopping_rounds=80,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_test_pred_cat = tunned_cat_model.predict(X_test_processed)\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_test_pred_cat))\n",
    "print(\"F1:\", f1_score(y_test, y_test_pred_cat))\n",
    "print('===================================================')\n",
    "y_train_pred_cat = tunned_cat_model.predict(X_train_processed)\n",
    "print(\"\\nClassification Report (Train):\")\n",
    "print(classification_report(y_train, y_train_pred_cat))\n",
    "print(\"F1:\", f1_score(y_train, y_train_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e84c6936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 7995/8000 [00:21<00:00]        "
     ]
    }
   ],
   "source": [
    "# SHAP feature importance\n",
    "explainer = shap.Explainer(tunned_cat_model, X_train_processed)\n",
    "shap_values = explainer(X_train_processed)\n",
    "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "# Create DF\n",
    "shap_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'SHAP_Value': mean_abs_shap\n",
    "}).sort_values(by='SHAP_Value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9fb546d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ready__NumOfProducts', 'num__Age', 'cat__Gender_Male', 'ready__ActivityScore', 'ready__IsActiveMember', 'cat__Geography_Germany', 'cat__AgeGroup_Senior', 'num__Balance', 'num__AgeProduct']\n"
     ]
    }
   ],
   "source": [
    "shap_df_cat = shap_df.reset_index()\n",
    "shap_df_cat['cumsum'] = shap_df_cat['SHAP_Value'].cumsum()\n",
    "shap_df_cat['cumsum_percent'] = 100 * shap_df_cat['cumsum'] / shap_df_cat['SHAP_Value'].sum()\n",
    "\n",
    "top_features = shap_df_cat[shap_df_cat['cumsum_percent'] <= 85]['Feature'].tolist()\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3cb249a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Feature</th>\n",
       "      <th>SHAP_Value</th>\n",
       "      <th>cumsum</th>\n",
       "      <th>cumsum_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>ready__NumOfProducts</td>\n",
       "      <td>0.625382</td>\n",
       "      <td>0.625382</td>\n",
       "      <td>21.629099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>num__Age</td>\n",
       "      <td>0.533949</td>\n",
       "      <td>1.159331</td>\n",
       "      <td>40.095963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>cat__Gender_Male</td>\n",
       "      <td>0.237244</td>\n",
       "      <td>1.396575</td>\n",
       "      <td>48.301154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>ready__ActivityScore</td>\n",
       "      <td>0.197086</td>\n",
       "      <td>1.593661</td>\n",
       "      <td>55.117461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>ready__IsActiveMember</td>\n",
       "      <td>0.193563</td>\n",
       "      <td>1.787223</td>\n",
       "      <td>61.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>cat__Geography_Germany</td>\n",
       "      <td>0.173982</td>\n",
       "      <td>1.961205</td>\n",
       "      <td>67.829147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>cat__AgeGroup_Senior</td>\n",
       "      <td>0.168332</td>\n",
       "      <td>2.129537</td>\n",
       "      <td>73.650971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>num__Balance</td>\n",
       "      <td>0.147881</td>\n",
       "      <td>2.277417</td>\n",
       "      <td>78.765487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>num__AgeProduct</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>2.388594</td>\n",
       "      <td>82.610591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                 Feature  SHAP_Value    cumsum  cumsum_percent\n",
       "0     22    ready__NumOfProducts    0.625382  0.625382       21.629099\n",
       "1      2                num__Age    0.533949  1.159331       40.095963\n",
       "2     11        cat__Gender_Male    0.237244  1.396575       48.301154\n",
       "3     18    ready__ActivityScore    0.197086  1.593661       55.117461\n",
       "4     19   ready__IsActiveMember    0.193563  1.787223       61.811911\n",
       "5      9  cat__Geography_Germany    0.173982  1.961205       67.829147\n",
       "6     13    cat__AgeGroup_Senior    0.168332  2.129537       73.650971\n",
       "7      3            num__Balance    0.147881  2.277417       78.765487\n",
       "8      7         num__AgeProduct    0.111177  2.388594       82.610591"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_df_cat[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dc854de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = shap_df_cat['Feature'][:9].tolist()\n",
    "top_feature_indices = [feature_names.index(feat) for feat in top_features]\n",
    "X_train_top = X_train_processed[:, top_feature_indices]\n",
    "X_test_top = X_test_processed[:, top_feature_indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d7c7c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1593\n",
      "           1       0.65      0.64      0.64       407\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.78      0.77      0.78      2000\n",
      "weighted avg       0.85      0.86      0.86      2000\n",
      "\n",
      "F1: 0.6418835192069393\n",
      "\n",
      "Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      6370\n",
      "           1       0.67      0.65      0.66      1630\n",
      "\n",
      "    accuracy                           0.86      8000\n",
      "   macro avg       0.79      0.78      0.79      8000\n",
      "weighted avg       0.86      0.86      0.86      8000\n",
      "\n",
      "F1: 0.6583385384134915\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_cat_model = CatBoostClassifier(**cat_best_params ,snapshot_file='cat_model.cbs')\n",
    "\n",
    "train_pool = Pool(X_train_top, y_train)\n",
    "valid_pool = Pool(X_test_top, y_test)\n",
    "\n",
    "final_cat_model.fit(\n",
    "    train_pool,\n",
    "    eval_set=valid_pool,\n",
    "    early_stopping_rounds=80,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_test_pred = final_cat_model.predict(X_test_top)\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_test_pred))\n",
    "\n",
    "y_train_pred = final_cat_model.predict(X_train_top)\n",
    "print(\"\\nClassification Report (Train):\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(\"F1:\", f1_score(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "837f2bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.43999999999999984 Best F1: 0.6424384525205158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probs = final_cat_model.predict_proba(X_test_top)[:,1]\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for thresh in np.arange(0.1, 0.9, 0.01):\n",
    "    preds = (probs > thresh).astype(int)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(\"Best threshold:\", best_thresh, \"Best F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c0db8",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b8ff732",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features=list(set(shap_df_cat['Feature'][:9].tolist() + shap_df_xgb['Feature'][:10].tolist()))\n",
    "\n",
    "top_feature_indices = [feature_names.index(feat) for feat in top_features]\n",
    "X_train_top = X_train_processed[:, top_feature_indices]\n",
    "X_test_top = X_test_processed[:, top_feature_indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "60e176ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Voting Classifier (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      1593\n",
      "           1       0.72      0.56      0.63       407\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.81      0.75      0.77      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n",
      "f1  0.6308539944903582\n",
      "Classification Report for Voting Classifier (Train):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      6370\n",
      "           1       0.75      0.59      0.66      1630\n",
      "\n",
      "    accuracy                           0.88      8000\n",
      "   macro avg       0.82      0.77      0.79      8000\n",
      "weighted avg       0.87      0.88      0.87      8000\n",
      "\n",
      "f1  0.6579490708878183\n"
     ]
    }
   ],
   "source": [
    "# voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', final_xgb_model),\n",
    "        ('cat', final_cat_model)\n",
    "    ],\n",
    "    voting='soft'  # Use 'soft' voting to average predicted probabilities\n",
    ")\n",
    "voting_clf.fit(X_train_top, y_train)\n",
    "y_test_pred_voting = voting_clf.predict(X_test_top)\n",
    "print(\"Classification Report for Voting Classifier (Test):\\n\", classification_report(y_test, y_test_pred_voting))    \n",
    "print('f1 ', f1_score(y_test, y_test_pred_voting))\n",
    "y_train_pred_voting = voting_clf.predict(X_train_top)\n",
    "print(\"Classification Report for Voting Classifier (Train):\\n\", classification_report(y_train, y_train_pred_voting))\n",
    "print('f1 ', f1_score(y_train, y_train_pred_voting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0b2dde0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.3599999999999999 Best F1: 0.6543352601156069\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probs = voting_clf.predict_proba(X_test_top)[:,1]\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for thresh in np.arange(0.1, 0.9, 0.01):\n",
    "    preds = (probs > thresh).astype(int)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(\"Best threshold:\", best_thresh, \"Best F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87240ad7",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6f14c",
   "metadata": {},
   "source": [
    "# save the final model and preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f916fc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models, checkpoints, and preprocessor saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import datetime\n",
    "\n",
    "# Base models directory\n",
    "BASE_MODEL_DIR = os.path.join(\"..\", \"models\")\n",
    "os.makedirs(BASE_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Timestamp for versioning\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb_dir = os.path.join(BASE_MODEL_DIR, f\"xgb_{timestamp}\")\n",
    "os.makedirs(xgb_dir, exist_ok=True)\n",
    "\n",
    "xgb_model_path = os.path.join(xgb_dir, \"model.pkl\")\n",
    "xgb_checkpoint_path = os.path.join(xgb_dir, \"checkpoint.json\")\n",
    "\n",
    "joblib.dump(final_xgb_model, xgb_model_path)\n",
    "final_xgb_model.save_model(xgb_checkpoint_path)\n",
    "\n",
    "# --- CatBoost ---\n",
    "cat_dir = os.path.join(BASE_MODEL_DIR, f\"catboost_{timestamp}\")\n",
    "os.makedirs(cat_dir, exist_ok=True)\n",
    "\n",
    "cat_model_path = os.path.join(cat_dir, \"model.pkl\")\n",
    "cat_checkpoint_path = os.path.join(cat_dir, \"checkpoint.cbs\")\n",
    "\n",
    "joblib.dump(final_cat_model, cat_model_path)\n",
    "final_cat_model.save_model(cat_checkpoint_path)\n",
    "\n",
    "# --- Preprocessor ---\n",
    "preprocessor_dir = os.path.join(BASE_MODEL_DIR, f\"preprocessor_{timestamp}\")\n",
    "os.makedirs(preprocessor_dir, exist_ok=True)\n",
    "\n",
    "preprocessor_path = os.path.join(preprocessor_dir, \"preprocessor.pkl\")\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "\n",
    "print(\"Models, checkpoints, and preprocessor saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e9dc35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
