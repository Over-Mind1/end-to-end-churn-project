{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09703e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import os\n",
    "import optuna\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0faada",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(),\"..\", \"data\", \"raw\", \"churn-data.csv\")\n",
    "df=pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c3ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48b0b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1ccb1",
   "metadata": {},
   "source": [
    "# feature engineering based on previous analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581d21d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   CreditScore            10000 non-null  int64  \n",
      " 1   Geography              10000 non-null  object \n",
      " 2   Gender                 10000 non-null  object \n",
      " 3   Age                    10000 non-null  int64  \n",
      " 4   Tenure                 10000 non-null  int64  \n",
      " 5   Balance                10000 non-null  float64\n",
      " 6   NumOfProducts          10000 non-null  int64  \n",
      " 7   HasCrCard              10000 non-null  int64  \n",
      " 8   IsActiveMember         10000 non-null  int64  \n",
      " 9   EstimatedSalary        10000 non-null  float64\n",
      " 10  Exited                 10000 non-null  int64  \n",
      " 11  IsZeroBalance          10000 non-null  int64  \n",
      " 12  AgeGroup               10000 non-null  object \n",
      " 13  CreditTier             10000 non-null  object \n",
      " 14  CustomerValue          10000 non-null  float64\n",
      " 15  AgeProduct             10000 non-null  float64\n",
      " 16  ActivityScore          10000 non-null  int64  \n",
      " 17  LogBalanceSalaryRatio  10000 non-null  float64\n",
      " 18  HighBalance            10000 non-null  int64  \n",
      " 19  CLV                    10000 non-null  float64\n",
      "dtypes: float64(6), int64(10), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "class FeatureEngineering:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    # Age groups mapping\n",
    "    def age_group(self, age):\n",
    "        if age < 30:\n",
    "            return \"Young\"\n",
    "        elif age < 45:\n",
    "            return \"Adult\"\n",
    "        elif age < 60:\n",
    "            return \"Senior\"\n",
    "        else:\n",
    "            return \"Elderly\"\n",
    "    # Credit score tiers mapping based on VantageScore\n",
    "    def credit_score_tier(self,score):\n",
    "        if score >= 781:\n",
    "            return \"superprime\"\n",
    "        elif score >= 661:\n",
    "            return \"prime\"\n",
    "        elif score >= 601:\n",
    "            return \"near prime\"\n",
    "        elif score >= 300:\n",
    "            return \"subprime\"\n",
    "        else:\n",
    "            return \"Very Poor\"\n",
    "    def make_feature_extraction(self):\n",
    "        df = self.df.copy()\n",
    "\n",
    "        # -------------------------\n",
    "        # 1. Zero balance indicator\n",
    "        # -------------------------\n",
    "        df[\"IsZeroBalance\"] = (df[\"Balance\"] == 0).astype(int)\n",
    "\n",
    "        # -------------------------\n",
    "        # 2. Age groups\n",
    "        # -------------------------\n",
    "        df[\"AgeGroup\"] = df[\"Age\"].apply(self.age_group)\n",
    "\n",
    "        # -------------------------\n",
    "        # 3. Credit score tiers VantageScore Credit Score\n",
    "        # -------------------------\n",
    "\n",
    "        df[\"CreditTier\"] = df[\"CreditScore\"].apply(self.credit_score_tier)\n",
    "\n",
    "        # -------------------------\n",
    "        # 4. Customer Value (improved)\n",
    "        # Balance + Salary is better indicator\n",
    "        # -------------------------\n",
    "        df[\"CustomerValue\"] = df[\"Balance\"] + df[\"EstimatedSalary\"]\n",
    "\n",
    "        # -------------------------\n",
    "        # 5. Age Ã— NumOfProducts\n",
    "        # -------------------------\n",
    "        df[\"AgeProduct\"] = np.log1p(df[\"Age\"] * df[\"NumOfProducts\"])\n",
    "\n",
    "        # -------------------------\n",
    "        # 6. Activity Score \n",
    "        # -------------------------\n",
    "        df[\"ActivityScore\"] = df[\"IsActiveMember\"] * df[\"NumOfProducts\"]\n",
    "\n",
    "        # -------------------------\n",
    "        # 7. Log Balance/Salary Ratio (BEST version)\n",
    "        # More stable, avoids skew\n",
    "        # -------------------------\n",
    "        df[\"LogBalanceSalaryRatio\"] = (\n",
    "            np.log1p(df[\"Balance\"]) - np.log1p(df[\"EstimatedSalary\"])\n",
    "        )\n",
    "\n",
    "        # -------------------------\n",
    "        # 8. High balance flag\n",
    "        # -------------------------\n",
    "        df[\"HighBalance\"] = (df[\"Balance\"] > df[\"Balance\"].median()).astype(int)\n",
    "\n",
    "        # -------------------------\n",
    "        # 9. Customer Lifetime Value (CLV)\n",
    "        # -------------------------\n",
    "        df[\"CLV\"] = df[\"Tenure\"] * df[\"Balance\"]\n",
    "\n",
    "        return df\n",
    "fe = FeatureEngineering(df)\n",
    "df_new_features = fe.make_feature_extraction()\n",
    "df_new_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48953361",
   "metadata": {},
   "source": [
    "# split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69f50c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features.to_csv(os.path.join(os.getcwd(),\"..\", \"data\", \"processed\", \"churn-data-features.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64ea43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (10000, 20)\n",
      "X_train shape: (9000, 19)\n",
      "X_test shape: (1000, 19)\n",
      "y_train shape: (9000,)\n",
      "y_test shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "X = df_new_features.drop('Exited', axis=1)\n",
    "y = df_new_features['Exited']\n",
    "\n",
    "#split the data into training and testing sets with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "# check shape of the splits\n",
    "print(\"df shape:\", df_new_features.shape)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730b7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature categories\n",
    "numerical_features = ['CreditScore', 'Tenure','Age', 'Balance', 'EstimatedSalary','LogBalanceSalaryRatio','CustomerValue','AgeProduct','CLV']\n",
    "categorical_features=['Geography', 'Gender','AgeGroup', 'CreditTier']\n",
    "ready_cols = list(set(X_train.columns.tolist()) - set(numerical_features) - set(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e876b3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>LogBalanceSalaryRatio</th>\n",
       "      <th>CustomerValue</th>\n",
       "      <th>AgeProduct</th>\n",
       "      <th>CLV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>640</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>118879.35</td>\n",
       "      <td>19131.71</td>\n",
       "      <td>1.826718</td>\n",
       "      <td>138011.06</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>713276.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>598</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>62979.93</td>\n",
       "      <td>152273.57</td>\n",
       "      <td>-0.882853</td>\n",
       "      <td>215253.50</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>62979.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>796</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>137262.71</td>\n",
       "      <td>62905.29</td>\n",
       "      <td>0.780258</td>\n",
       "      <td>200168.00</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>274525.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8469</th>\n",
       "      <td>720</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>183135.39</td>\n",
       "      <td>197688.50</td>\n",
       "      <td>-0.076466</td>\n",
       "      <td>380823.89</td>\n",
       "      <td>4.962845</td>\n",
       "      <td>915676.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8563</th>\n",
       "      <td>578</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>148600.91</td>\n",
       "      <td>143397.14</td>\n",
       "      <td>0.035646</td>\n",
       "      <td>291998.05</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>148600.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Tenure  Age    Balance  EstimatedSalary  \\\n",
       "673           640       6   32  118879.35         19131.71   \n",
       "7709          598       1   64   62979.93        152273.57   \n",
       "6100          796       2   30  137262.71         62905.29   \n",
       "8469          720       5   71  183135.39        197688.50   \n",
       "8563          578       1   45  148600.91        143397.14   \n",
       "\n",
       "      LogBalanceSalaryRatio  CustomerValue  AgeProduct        CLV  \n",
       "673                1.826718      138011.06    4.174387  713276.10  \n",
       "7709              -0.882853      215253.50    4.174387   62979.93  \n",
       "6100               0.780258      200168.00    4.110874  274525.42  \n",
       "8469              -0.076466      380823.89    4.962845  915676.95  \n",
       "8563               0.035646      291998.05    3.828641  148600.91  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[numerical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f0e849d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns.tolist()) == len(ready_cols)+len(numerical_features)+len(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f376db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of numerical features:\n",
      " Age                      1.024857\n",
      "CLV                      0.869551\n",
      "AgeProduct               0.264745\n",
      "Tenure                   0.009788\n",
      "EstimatedSalary          0.009628\n",
      "CustomerValue           -0.068203\n",
      "CreditScore             -0.078800\n",
      "Balance                 -0.143684\n",
      "LogBalanceSalaryRatio   -0.538818\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check skewness of numerical features\n",
    "skewed_feats = X_train[numerical_features].skew().sort_values(ascending=False)\n",
    "print(\"Skewness of numerical features:\\n\", skewed_feats)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90796bc0",
   "metadata": {},
   "source": [
    "# pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9facacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for non skewed numerical features\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "\n",
    "\n",
    "#for categorical features\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',sparse_output=False, drop='first'))\n",
    "])\n",
    "\n",
    "\n",
    "#for ready to use features\n",
    "ready_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Combine all pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, numerical_features),\n",
    "        ('cat', cat_pipeline, categorical_features),\n",
    "        ('ready', ready_pipeline, ready_cols)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6599bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed X_train shape: (9000, 24)\n",
      "Processed X_test shape: (1000, 24)\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------\n",
    "# add noise features to test preprocessing robustness\n",
    "#---------------------------------------------------------\n",
    "\n",
    "# num_noise_features = 1\n",
    "# for i in range(num_noise_features):\n",
    "#     noise_feature_name = f'NoiseFeature_{i+1}'\n",
    "#     X_train[noise_feature_name] = np.random.rand(X_train.shape[0])\n",
    "#     X_test[noise_feature_name] = np.random.rand(X_test.shape[0])\n",
    "#     ready_cols.append(noise_feature_name)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# Fit and transform the training data\n",
    "#---------------------------------------------------------\n",
    "X_train_processed = preprocessor.fit_transform(X_train) \n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "print(\"Processed X_train shape:\", X_train_processed.shape)\n",
    "print(\"Processed X_test shape:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accf1ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(0.6278777731268314), 1: np.float64(2.454991816693944)}\n"
     ]
    }
   ],
   "source": [
    "#compute class weights to handle class imbalance\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i : class_weights[i] for i in range(len(class_weights))}\n",
    "print(\"Class weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36699ac6",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750d8ae",
   "metadata": {},
   "source": [
    "# baseline xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cec9ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89       796\n",
      "           1       0.55      0.64      0.59       204\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.73      0.75      0.74      1000\n",
      "weighted avg       0.83      0.82      0.83      1000\n",
      "\n",
      "f1  0.592255125284738\n",
      "===========================================================\n",
      "Classification Report for Training Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      7167\n",
      "           1       0.85      0.98      0.91      1833\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.92      0.97      0.94      9000\n",
      "weighted avg       0.97      0.96      0.96      9000\n",
      "\n",
      "f1  0.9129113924050632\n"
     ]
    }
   ],
   "source": [
    "# xgboost model with smote\n",
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=class_weights_dict[1]/class_weights_dict[0], random_state=42)\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_processed)\n",
    "print(\"Classification Report for Test Set:\\n\", classification_report(y_test, y_test_pred_xgb))\n",
    "print('f1 ', f1_score(y_test, y_test_pred_xgb))\n",
    "print('===========================================================')\n",
    "y_train_pred_xgb = xgb_model.predict(X_train_processed)\n",
    "print(\"Classification Report for Training Set:\\n\", classification_report(y_train, y_train_pred_xgb))\n",
    "print('f1 ', f1_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012bee90",
   "metadata": {},
   "source": [
    "#  XGBoost hyperparameters tunning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fbfe0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    # XGBoost hyperparameters\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"use_label_encoder\": False,\n",
    "\n",
    "        # Class imbalance handling\n",
    "        \"scale_pos_weight\": class_weights_dict[1] / class_weights_dict[0],\n",
    "\n",
    "        # Trial suggestions\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10)\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train_processed, y_train)\n",
    "\n",
    "    preds = model.predict(X_test_processed)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1a305d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 17:08:36,858] A new study created in memory with name: no-name-6a3d7a1c-078a-4829-b60f-5b6b960baf25\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:36] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:37,294] Trial 0 finished with value: 0.6160520607375272 and parameters: {'n_estimators': 245, 'max_depth': 8, 'learning_rate': 0.018726990310762685, 'subsample': 0.6866138876692973, 'colsample_bytree': 0.8150715674727202, 'gamma': 4.926588432699576, 'min_child_weight': 1}. Best is trial 0 with value: 0.6160520607375272.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:37] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:37,419] Trial 1 finished with value: 0.6037735849056604 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.12039332478994154, 'subsample': 0.7927232387876402, 'colsample_bytree': 0.7983841669454286, 'gamma': 2.379849880145416, 'min_child_weight': 5}. Best is trial 0 with value: 0.6160520607375272.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:37] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:37,464] Trial 2 finished with value: 0.6027944111776448 and parameters: {'n_estimators': 61, 'max_depth': 5, 'learning_rate': 0.19209643652579514, 'subsample': 0.8831261535496735, 'colsample_bytree': 0.5295775482977012, 'gamma': 2.7512077526532828, 'min_child_weight': 7}. Best is trial 0 with value: 0.6160520607375272.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:37] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:37,599] Trial 3 finished with value: 0.596244131455399 and parameters: {'n_estimators': 115, 'max_depth': 8, 'learning_rate': 0.28344968398216525, 'subsample': 0.7457073370257472, 'colsample_bytree': 0.9749925629927092, 'gamma': 1.9753010543882037, 'min_child_weight': 4}. Best is trial 0 with value: 0.6160520607375272.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:37] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:37,815] Trial 4 finished with value: 0.6262626262626263 and parameters: {'n_estimators': 255, 'max_depth': 5, 'learning_rate': 0.042488163006669556, 'subsample': 0.8157050361127722, 'colsample_bytree': 0.8660281741887383, 'gamma': 4.850226504663723, 'min_child_weight': 2}. Best is trial 4 with value: 0.6262626262626263.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:37] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:37,886] Trial 5 finished with value: 0.6197183098591549 and parameters: {'n_estimators': 205, 'max_depth': 4, 'learning_rate': 0.2613782689310749, 'subsample': 0.9388019977560456, 'colsample_bytree': 0.9733589664592512, 'gamma': 3.176453703085789, 'min_child_weight': 2}. Best is trial 4 with value: 0.6262626262626263.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:37] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:38,043] Trial 6 finished with value: 0.5869074492099323 and parameters: {'n_estimators': 232, 'max_depth': 7, 'learning_rate': 0.28425708728800103, 'subsample': 0.6072406993356152, 'colsample_bytree': 0.965184181578042, 'gamma': 2.73997436449106, 'min_child_weight': 9}. Best is trial 4 with value: 0.6262626262626263.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:38] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:38,357] Trial 7 finished with value: 0.6123348017621145 and parameters: {'n_estimators': 271, 'max_depth': 10, 'learning_rate': 0.026529313968247585, 'subsample': 0.5202213461314596, 'colsample_bytree': 0.5183536864350455, 'gamma': 3.028102009357314, 'min_child_weight': 4}. Best is trial 4 with value: 0.6262626262626263.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:38] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:38,611] Trial 8 finished with value: 0.6128364389233955 and parameters: {'n_estimators': 292, 'max_depth': 7, 'learning_rate': 0.022290157398909955, 'subsample': 0.9840322841341375, 'colsample_bytree': 0.6628472467820771, 'gamma': 3.3527426166985945, 'min_child_weight': 8}. Best is trial 4 with value: 0.6262626262626263.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:38] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:38,839] Trial 9 finished with value: 0.630071599045346 and parameters: {'n_estimators': 209, 'max_depth': 7, 'learning_rate': 0.11026202636557285, 'subsample': 0.7285600393510063, 'colsample_bytree': 0.9428431417974359, 'gamma': 1.2668145888122462, 'min_child_weight': 1}. Best is trial 9 with value: 0.630071599045346.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:38] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:39,066] Trial 10 finished with value: 0.5906976744186047 and parameters: {'n_estimators': 139, 'max_depth': 12, 'learning_rate': 0.11152090032400583, 'subsample': 0.6506376056524874, 'colsample_bytree': 0.6813838928775771, 'gamma': 0.01624616860799799, 'min_child_weight': 10}. Best is trial 9 with value: 0.630071599045346.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:39] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:39,140] Trial 11 finished with value: 0.6153846153846154 and parameters: {'n_estimators': 162, 'max_depth': 3, 'learning_rate': 0.0786336601321046, 'subsample': 0.8167991771347107, 'colsample_bytree': 0.8726225257185884, 'gamma': 1.005476223645304, 'min_child_weight': 2}. Best is trial 9 with value: 0.630071599045346.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:39] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:39,236] Trial 12 finished with value: 0.6153846153846154 and parameters: {'n_estimators': 238, 'max_depth': 6, 'learning_rate': 0.18538411378141914, 'subsample': 0.854926580414689, 'colsample_bytree': 0.888081684408817, 'gamma': 4.855799369724815, 'min_child_weight': 1}. Best is trial 9 with value: 0.630071599045346.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:39] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:39,520] Trial 13 finished with value: 0.6018957345971564 and parameters: {'n_estimators': 201, 'max_depth': 10, 'learning_rate': 0.07157079605707847, 'subsample': 0.7350136410882901, 'colsample_bytree': 0.8885907889230422, 'gamma': 1.3734895624857366, 'min_child_weight': 3}. Best is trial 9 with value: 0.630071599045346.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:39] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:39,647] Trial 14 finished with value: 0.6209677419354839 and parameters: {'n_estimators': 297, 'max_depth': 3, 'learning_rate': 0.07760876589895824, 'subsample': 0.5927389741631388, 'colsample_bytree': 0.7464485208782098, 'gamma': 4.059874933353138, 'min_child_weight': 6}. Best is trial 9 with value: 0.630071599045346.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:39] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:40,096] Trial 15 finished with value: 0.5786802030456852 and parameters: {'n_estimators': 261, 'max_depth': 9, 'learning_rate': 0.14062741806719797, 'subsample': 0.707429785425429, 'colsample_bytree': 0.906723059864093, 'gamma': 0.5979439523094054, 'min_child_weight': 3}. Best is trial 9 with value: 0.630071599045346.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:40,203] Trial 16 finished with value: 0.6369426751592356 and parameters: {'n_estimators': 217, 'max_depth': 6, 'learning_rate': 0.17838144474070727, 'subsample': 0.7896381389436805, 'colsample_bytree': 0.8185292181985635, 'gamma': 3.9894069937324597, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:40,287] Trial 17 finished with value: 0.6033755274261603 and parameters: {'n_estimators': 169, 'max_depth': 6, 'learning_rate': 0.2217990874104283, 'subsample': 0.8923691009153759, 'colsample_bytree': 0.7522392713130224, 'gamma': 3.9819447432909127, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:40,444] Trial 18 finished with value: 0.6084905660377359 and parameters: {'n_estimators': 209, 'max_depth': 12, 'learning_rate': 0.1659010381767984, 'subsample': 0.7731537964343602, 'colsample_bytree': 0.6325094953760304, 'gamma': 1.9313158831438684, 'min_child_weight': 5}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:40,562] Trial 19 finished with value: 0.5833333333333334 and parameters: {'n_estimators': 143, 'max_depth': 9, 'learning_rate': 0.22070081242047515, 'subsample': 0.6559380969195254, 'colsample_bytree': 0.8198788328992027, 'gamma': 3.667727110208594, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:40,663] Trial 20 finished with value: 0.6133909287257019 and parameters: {'n_estimators': 102, 'max_depth': 6, 'learning_rate': 0.11451655316244708, 'subsample': 0.5469428800086342, 'colsample_bytree': 0.745471077970791, 'gamma': 1.9586864150929268, 'min_child_weight': 4}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:40,802] Trial 21 finished with value: 0.6272912423625254 and parameters: {'n_estimators': 226, 'max_depth': 5, 'learning_rate': 0.052374631237936065, 'subsample': 0.8336736883454239, 'colsample_bytree': 0.9288608694055909, 'gamma': 4.463902146933872, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:40,911] Trial 22 finished with value: 0.6101010101010101 and parameters: {'n_estimators': 228, 'max_depth': 4, 'learning_rate': 0.14572168866297758, 'subsample': 0.8461643552430749, 'colsample_bytree': 0.9301771491779574, 'gamma': 4.352836457468775, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:40] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:41,076] Trial 23 finished with value: 0.620253164556962 and parameters: {'n_estimators': 182, 'max_depth': 7, 'learning_rate': 0.05840979863404902, 'subsample': 0.7631855043685627, 'colsample_bytree': 0.933884458216436, 'gamma': 4.379260141097022, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:41] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:41,186] Trial 24 finished with value: 0.6255144032921811 and parameters: {'n_estimators': 222, 'max_depth': 6, 'learning_rate': 0.09898292038801976, 'subsample': 0.9326653566320666, 'colsample_bytree': 0.9994416191030482, 'gamma': 3.5042339287605055, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:41] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:41,328] Trial 25 finished with value: 0.6203904555314533 and parameters: {'n_estimators': 277, 'max_depth': 4, 'learning_rate': 0.16629410168313044, 'subsample': 0.71601772060844, 'colsample_bytree': 0.8409868510200162, 'gamma': 1.3205128993483848, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:41] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:41,442] Trial 26 finished with value: 0.6032388663967612 and parameters: {'n_estimators': 208, 'max_depth': 5, 'learning_rate': 0.09281136843274895, 'subsample': 0.799840253990488, 'colsample_bytree': 0.7794304234945806, 'gamma': 4.424616675916844, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:41] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:41,535] Trial 27 finished with value: 0.6302521008403361 and parameters: {'n_estimators': 184, 'max_depth': 7, 'learning_rate': 0.20173559091111776, 'subsample': 0.8542423099780069, 'colsample_bytree': 0.9277791140544203, 'gamma': 3.9836541326662807, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:41] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:41,623] Trial 28 finished with value: 0.610989010989011 and parameters: {'n_estimators': 176, 'max_depth': 8, 'learning_rate': 0.22346437941460837, 'subsample': 0.8857127319753939, 'colsample_bytree': 0.8507330621573828, 'gamma': 3.802352972984307, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:41] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:41,763] Trial 29 finished with value: 0.6018518518518519 and parameters: {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.19461903854282708, 'subsample': 0.6607803803457093, 'colsample_bytree': 0.9438271060651688, 'gamma': 2.338270440523278, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:41] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:41,885] Trial 30 finished with value: 0.6018957345971564 and parameters: {'n_estimators': 126, 'max_depth': 7, 'learning_rate': 0.24339014640876655, 'subsample': 0.7698438518384604, 'colsample_bytree': 0.8264908215761234, 'gamma': 0.39497679293618615, 'min_child_weight': 6}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:41] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:42,002] Trial 31 finished with value: 0.6061855670103092 and parameters: {'n_estimators': 246, 'max_depth': 6, 'learning_rate': 0.1323648946305906, 'subsample': 0.8365997641506557, 'colsample_bytree': 0.90252532925078, 'gamma': 4.6395829217292155, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:42,122] Trial 32 finished with value: 0.6131078224101479 and parameters: {'n_estimators': 194, 'max_depth': 5, 'learning_rate': 0.16316718678305472, 'subsample': 0.6897130652431119, 'colsample_bytree': 0.998988038445903, 'gamma': 4.145178902717886, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:42,204] Trial 33 finished with value: 0.6025641025641025 and parameters: {'n_estimators': 188, 'max_depth': 9, 'learning_rate': 0.2027239599625073, 'subsample': 0.9114118566269991, 'colsample_bytree': 0.7865173662125964, 'gamma': 3.8530567684818147, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:42,295] Trial 34 finished with value: 0.6128364389233955 and parameters: {'n_estimators': 219, 'max_depth': 7, 'learning_rate': 0.17810416415702565, 'subsample': 0.8662945546209226, 'colsample_bytree': 0.9195139736148145, 'gamma': 4.944832862755557, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:42,454] Trial 35 finished with value: 0.6219512195121951 and parameters: {'n_estimators': 246, 'max_depth': 5, 'learning_rate': 0.04527410463455643, 'subsample': 0.7869833125350733, 'colsample_bytree': 0.9516251030542074, 'gamma': 4.577950531377773, 'min_child_weight': 4}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:42,595] Trial 36 finished with value: 0.6035242290748899 and parameters: {'n_estimators': 91, 'max_depth': 8, 'learning_rate': 0.12822056070393, 'subsample': 0.7423079545824703, 'colsample_bytree': 0.853683394258292, 'gamma': 2.8078997547391342, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:42,725] Trial 37 finished with value: 0.5987261146496815 and parameters: {'n_estimators': 217, 'max_depth': 6, 'learning_rate': 0.26242406889022696, 'subsample': 0.824501794760196, 'colsample_bytree': 0.9731663936959245, 'gamma': 3.4457746286588966, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:42,823] Trial 38 finished with value: 0.6125760649087221 and parameters: {'n_estimators': 160, 'max_depth': 4, 'learning_rate': 0.19971609255117698, 'subsample': 0.9784272393753825, 'colsample_bytree': 0.8067675500312096, 'gamma': 2.2566203812027767, 'min_child_weight': 5}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:42] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:42,989] Trial 39 finished with value: 0.6021052631578947 and parameters: {'n_estimators': 193, 'max_depth': 7, 'learning_rate': 0.14746206303435122, 'subsample': 0.8035982463728423, 'colsample_bytree': 0.5769660406896834, 'gamma': 3.0381347436028374, 'min_child_weight': 7}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:43] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:43,314] Trial 40 finished with value: 0.6219512195121951 and parameters: {'n_estimators': 235, 'max_depth': 5, 'learning_rate': 0.04399943110163856, 'subsample': 0.9472615344508493, 'colsample_bytree': 0.6993114552137445, 'gamma': 4.150541502629167, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:43] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:43,530] Trial 41 finished with value: 0.6244897959183674 and parameters: {'n_estimators': 265, 'max_depth': 6, 'learning_rate': 0.0180348981244121, 'subsample': 0.8213002042300156, 'colsample_bytree': 0.8738057893862007, 'gamma': 4.7060625268099034, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:43] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:43,812] Trial 42 finished with value: 0.623015873015873 and parameters: {'n_estimators': 251, 'max_depth': 4, 'learning_rate': 0.03157755044282427, 'subsample': 0.8616788874564345, 'colsample_bytree': 0.8610241658504221, 'gamma': 4.922029287329694, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:43] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:44,017] Trial 43 finished with value: 0.6307053941908713 and parameters: {'n_estimators': 281, 'max_depth': 5, 'learning_rate': 0.05323261082887838, 'subsample': 0.7357699127538118, 'colsample_bytree': 0.961111321959927, 'gamma': 4.397659198125608, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:44] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:44,100] Trial 44 finished with value: 0.6153846153846154 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.0566862529768719, 'subsample': 0.7164964258291889, 'colsample_bytree': 0.9604806346417084, 'gamma': 3.6131874547237333, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:44] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:44,233] Trial 45 finished with value: 0.625531914893617 and parameters: {'n_estimators': 206, 'max_depth': 7, 'learning_rate': 0.10018154864219826, 'subsample': 0.7892840155067985, 'colsample_bytree': 0.9804412304596575, 'gamma': 4.304026123209475, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:44] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:44,681] Trial 46 finished with value: 0.6190476190476191 and parameters: {'n_estimators': 284, 'max_depth': 3, 'learning_rate': 0.06742102191448658, 'subsample': 0.7437875015339188, 'colsample_bytree': 0.9112566762525246, 'gamma': 3.2448327003623905, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:44] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:45,567] Trial 47 finished with value: 0.6119733924611973 and parameters: {'n_estimators': 236, 'max_depth': 6, 'learning_rate': 0.0819514184150207, 'subsample': 0.6787265899021105, 'colsample_bytree': 0.9464496961755984, 'gamma': 1.6984088427450237, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:45] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:46,039] Trial 48 finished with value: 0.6088794926004228 and parameters: {'n_estimators': 182, 'max_depth': 8, 'learning_rate': 0.012682314040406213, 'subsample': 0.6188461981873179, 'colsample_bytree': 0.8904402006974701, 'gamma': 2.642315759625796, 'min_child_weight': 4}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:46] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:46,920] Trial 49 finished with value: 0.5932203389830508 and parameters: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.17831739654122916, 'subsample': 0.7294531880342158, 'colsample_bytree': 0.9806155896698543, 'gamma': 3.913051735080873, 'min_child_weight': 10}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:46] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:47,108] Trial 50 finished with value: 0.5846867749419954 and parameters: {'n_estimators': 262, 'max_depth': 5, 'learning_rate': 0.20825648311538963, 'subsample': 0.7639998628696784, 'colsample_bytree': 0.9210772486529324, 'gamma': 1.0120574505186855, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:47] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:47,690] Trial 51 finished with value: 0.6268041237113402 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.037643909417186455, 'subsample': 0.8102626285819465, 'colsample_bytree': 0.8787774222319531, 'gamma': 4.609611182251437, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:47] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:48,327] Trial 52 finished with value: 0.620253164556962 and parameters: {'n_estimators': 224, 'max_depth': 7, 'learning_rate': 0.028125688284340214, 'subsample': 0.834142945442898, 'colsample_bytree': 0.8799635468149691, 'gamma': 4.692793469537386, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:48] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:48,625] Trial 53 finished with value: 0.629399585921325 and parameters: {'n_estimators': 273, 'max_depth': 6, 'learning_rate': 0.05517844987944099, 'subsample': 0.8708409798213748, 'colsample_bytree': 0.9019635936876781, 'gamma': 4.226275169061066, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:48] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:48,779] Trial 54 finished with value: 0.6335403726708074 and parameters: {'n_estimators': 299, 'max_depth': 6, 'learning_rate': 0.06023510736385577, 'subsample': 0.8860640290468725, 'colsample_bytree': 0.9019995102526159, 'gamma': 4.126415009473424, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:48] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:48,932] Trial 55 finished with value: 0.6286919831223629 and parameters: {'n_estimators': 298, 'max_depth': 6, 'learning_rate': 0.06863523324936197, 'subsample': 0.8968054549589809, 'colsample_bytree': 0.8370705737108556, 'gamma': 4.177849808604777, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:48] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:49,075] Trial 56 finished with value: 0.6153846153846154 and parameters: {'n_estimators': 278, 'max_depth': 7, 'learning_rate': 0.09248012200263364, 'subsample': 0.9226457255513446, 'colsample_bytree': 0.9071496688767658, 'gamma': 3.6630234065108396, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:49] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:49,464] Trial 57 finished with value: 0.5991189427312775 and parameters: {'n_estimators': 271, 'max_depth': 8, 'learning_rate': 0.299187472257647, 'subsample': 0.8764567956830357, 'colsample_bytree': 0.964264670372935, 'gamma': 3.7884212484581496, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:49] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:49,661] Trial 58 finished with value: 0.6242299794661191 and parameters: {'n_estimators': 296, 'max_depth': 7, 'learning_rate': 0.12001022810055123, 'subsample': 0.9466288888253948, 'colsample_bytree': 0.7193739044637693, 'gamma': 4.022955671917572, 'min_child_weight': 9}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:49] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:49,891] Trial 59 finished with value: 0.6170212765957447 and parameters: {'n_estimators': 288, 'max_depth': 6, 'learning_rate': 0.08311758131761637, 'subsample': 0.8471180141984292, 'colsample_bytree': 0.8974235884820088, 'gamma': 3.2954605223552873, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:49] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:50,323] Trial 60 finished with value: 0.6072186836518046 and parameters: {'n_estimators': 277, 'max_depth': 6, 'learning_rate': 0.10688908581450421, 'subsample': 0.7022762413757452, 'colsample_bytree': 0.9364855855309915, 'gamma': 4.288312438900267, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:50] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:50,661] Trial 61 finished with value: 0.6278586278586279 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.06844409858708837, 'subsample': 0.8923913225046186, 'colsample_bytree': 0.8302140083805974, 'gamma': 4.137440153666518, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:50] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:50,815] Trial 62 finished with value: 0.6223175965665236 and parameters: {'n_estimators': 293, 'max_depth': 7, 'learning_rate': 0.06046237094945788, 'subsample': 0.9037388843680381, 'colsample_bytree': 0.7703272970260974, 'gamma': 4.2216135575966796, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:50] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:51,096] Trial 63 finished with value: 0.6172839506172839 and parameters: {'n_estimators': 282, 'max_depth': 6, 'learning_rate': 0.053535148800208765, 'subsample': 0.9643937291431657, 'colsample_bytree': 0.7972890602743713, 'gamma': 4.489160148490108, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:51,564] Trial 64 finished with value: 0.6301969365426696 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0870363990141435, 'subsample': 0.8708809900688906, 'colsample_bytree': 0.8461335730204689, 'gamma': 0.02390998392377197, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:51,928] Trial 65 finished with value: 0.5661375661375662 and parameters: {'n_estimators': 199, 'max_depth': 11, 'learning_rate': 0.18519184599095542, 'subsample': 0.8722301692280874, 'colsample_bytree': 0.862247427817628, 'gamma': 0.15870013507263084, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:52,197] Trial 66 finished with value: 0.5857142857142857 and parameters: {'n_estimators': 267, 'max_depth': 5, 'learning_rate': 0.2124048894212975, 'subsample': 0.7804880682298673, 'colsample_bytree': 0.9275269186809012, 'gamma': 1.0561012347104448, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:52] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:52,380] Trial 67 finished with value: 0.625 and parameters: {'n_estimators': 215, 'max_depth': 4, 'learning_rate': 0.07862349492125792, 'subsample': 0.9187028654840605, 'colsample_bytree': 0.8924666148406969, 'gamma': 0.6957117854287767, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:52] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:52,657] Trial 68 finished with value: 0.6147186147186147 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.08758796367785773, 'subsample': 0.8525275071988905, 'colsample_bytree': 0.9517824950920869, 'gamma': 1.4207674156178074, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:52] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:53,041] Trial 69 finished with value: 0.576271186440678 and parameters: {'n_estimators': 163, 'max_depth': 7, 'learning_rate': 0.23527960370020584, 'subsample': 0.7604797949564801, 'colsample_bytree': 0.8196828439253556, 'gamma': 0.7091376000324431, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:53] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:53,499] Trial 70 finished with value: 0.6073059360730594 and parameters: {'n_estimators': 176, 'max_depth': 6, 'learning_rate': 0.15801298614608494, 'subsample': 0.8754168934897597, 'colsample_bytree': 0.9901921733715076, 'gamma': 0.39366690113136765, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:53] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:53,711] Trial 71 finished with value: 0.6276150627615062 and parameters: {'n_estimators': 292, 'max_depth': 6, 'learning_rate': 0.06692050791014147, 'subsample': 0.904029610339936, 'colsample_bytree': 0.8430592310618343, 'gamma': 4.813965103808053, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:53] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:53,898] Trial 72 finished with value: 0.634453781512605 and parameters: {'n_estimators': 288, 'max_depth': 6, 'learning_rate': 0.04716096045749018, 'subsample': 0.8906298698423957, 'colsample_bytree': 0.913740586471675, 'gamma': 3.9666245937456535, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:53] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:54,460] Trial 73 finished with value: 0.6260162601626016 and parameters: {'n_estimators': 287, 'max_depth': 5, 'learning_rate': 0.03816547867292499, 'subsample': 0.927242885617353, 'colsample_bytree': 0.9170033894775177, 'gamma': 4.029587686245614, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:54] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:55,208] Trial 74 finished with value: 0.6290672451193059 and parameters: {'n_estimators': 256, 'max_depth': 7, 'learning_rate': 0.045720678886724944, 'subsample': 0.725920325983806, 'colsample_bytree': 0.9384928868774441, 'gamma': 3.4901124677883546, 'min_child_weight': 2}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:55] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:55,970] Trial 75 finished with value: 0.6147368421052631 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05210003771574204, 'subsample': 0.8889849448803085, 'colsample_bytree': 0.957039596817864, 'gamma': 3.7556120153657186, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:56] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:56,235] Trial 76 finished with value: 0.609271523178808 and parameters: {'n_estimators': 279, 'max_depth': 5, 'learning_rate': 0.1724439127438484, 'subsample': 0.8554462041596032, 'colsample_bytree': 0.8719052967776215, 'gamma': 1.7531245662539148, 'min_child_weight': 1}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:56] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:56,750] Trial 77 finished with value: 0.631578947368421 and parameters: {'n_estimators': 271, 'max_depth': 4, 'learning_rate': 0.07522275055982516, 'subsample': 0.837811528810041, 'colsample_bytree': 0.9179543401009103, 'gamma': 3.94057772309682, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:56] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:56,958] Trial 78 finished with value: 0.6144578313253012 and parameters: {'n_estimators': 290, 'max_depth': 3, 'learning_rate': 0.10465976285612971, 'subsample': 0.825331808113374, 'colsample_bytree': 0.9730203167093913, 'gamma': 3.031843584718696, 'min_child_weight': 5}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:56] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:57,266] Trial 79 finished with value: 0.623015873015873 and parameters: {'n_estimators': 189, 'max_depth': 4, 'learning_rate': 0.07322250816051562, 'subsample': 0.7934012056084201, 'colsample_bytree': 0.9257697722905351, 'gamma': 3.9267371222644507, 'min_child_weight': 6}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:57] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:57,440] Trial 80 finished with value: 0.6290322580645161 and parameters: {'n_estimators': 243, 'max_depth': 4, 'learning_rate': 0.09248555085393913, 'subsample': 0.7520232961056743, 'colsample_bytree': 0.8529836284502832, 'gamma': 4.408006758344735, 'min_child_weight': 7}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:57] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:57,679] Trial 81 finished with value: 0.6337448559670782 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.06413987420449402, 'subsample': 0.8415530889569713, 'colsample_bytree': 0.8999152722102218, 'gamma': 3.604489727319938, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:57] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:58,005] Trial 82 finished with value: 0.6224899598393574 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.06255397947327429, 'subsample': 0.8390831077154209, 'colsample_bytree': 0.8856076413561847, 'gamma': 3.5689436460045236, 'min_child_weight': 4}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:58] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:58,274] Trial 83 finished with value: 0.6147368421052631 and parameters: {'n_estimators': 269, 'max_depth': 4, 'learning_rate': 0.18880502261960153, 'subsample': 0.7762111182323671, 'colsample_bytree': 0.9098364329925355, 'gamma': 3.7415608655050385, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:58] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:58,454] Trial 84 finished with value: 0.6363636363636364 and parameters: {'n_estimators': 284, 'max_depth': 4, 'learning_rate': 0.07476318499882059, 'subsample': 0.8009687868827847, 'colsample_bytree': 0.9467422136395319, 'gamma': 0.001312423054732205, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:58] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:58,660] Trial 85 finished with value: 0.6123260437375746 and parameters: {'n_estimators': 281, 'max_depth': 4, 'learning_rate': 0.034144213418655645, 'subsample': 0.8115370635791332, 'colsample_bytree': 0.9472731754214954, 'gamma': 3.395680250633704, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:58] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:58,806] Trial 86 finished with value: 0.6307385229540918 and parameters: {'n_estimators': 251, 'max_depth': 3, 'learning_rate': 0.07527453489856803, 'subsample': 0.8077212324272209, 'colsample_bytree': 0.6333782542070653, 'gamma': 0.16080696868146221, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:58] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:59,214] Trial 87 finished with value: 0.6181102362204725 and parameters: {'n_estimators': 266, 'max_depth': 3, 'learning_rate': 0.022960492421965614, 'subsample': 0.8055173985523209, 'colsample_bytree': 0.5941090476268942, 'gamma': 0.3736285938545288, 'min_child_weight': 4}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:59] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:59,342] Trial 88 finished with value: 0.6150793650793651 and parameters: {'n_estimators': 252, 'max_depth': 3, 'learning_rate': 0.04599855375180628, 'subsample': 0.8314008298832145, 'colsample_bytree': 0.6489728907933293, 'gamma': 0.17485316812552038, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:59] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:59,547] Trial 89 finished with value: 0.6297029702970297 and parameters: {'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.07487491339043066, 'subsample': 0.8207148518495335, 'colsample_bytree': 0.5773233747832163, 'gamma': 3.9746226417168677, 'min_child_weight': 4}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:59] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:08:59,864] Trial 90 finished with value: 0.6202783300198808 and parameters: {'n_estimators': 261, 'max_depth': 4, 'learning_rate': 0.06331629172437081, 'subsample': 0.8452394311084553, 'colsample_bytree': 0.759368879180107, 'gamma': 4.476951665066394, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:08:59] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:00,440] Trial 91 finished with value: 0.6357894736842106 and parameters: {'n_estimators': 293, 'max_depth': 5, 'learning_rate': 0.08565797574251227, 'subsample': 0.8667406193535652, 'colsample_bytree': 0.5095115090280762, 'gamma': 0.10161136809654675, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:00] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:00,917] Trial 92 finished with value: 0.6232741617357002 and parameters: {'n_estimators': 274, 'max_depth': 3, 'learning_rate': 0.05008258299191447, 'subsample': 0.8007686159138493, 'colsample_bytree': 0.5212018510964511, 'gamma': 0.5253955727007634, 'min_child_weight': 4}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:00] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:01,217] Trial 93 finished with value: 0.6211180124223602 and parameters: {'n_estimators': 284, 'max_depth': 4, 'learning_rate': 0.09980224123732546, 'subsample': 0.8635563492158247, 'colsample_bytree': 0.6916323867046826, 'gamma': 2.150939390471322, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:01] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:01,430] Trial 94 finished with value: 0.6304801670146137 and parameters: {'n_estimators': 288, 'max_depth': 5, 'learning_rate': 0.0749545214142955, 'subsample': 0.792230087376513, 'colsample_bytree': 0.6153434857770212, 'gamma': 0.2089287868807269, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:01] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:02,087] Trial 95 finished with value: 0.602510460251046 and parameters: {'n_estimators': 289, 'max_depth': 5, 'learning_rate': 0.07771539457456472, 'subsample': 0.786353523629793, 'colsample_bytree': 0.5438321480347366, 'gamma': 0.2168646556397506, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:02] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:02,250] Trial 96 finished with value: 0.6129032258064516 and parameters: {'n_estimators': 281, 'max_depth': 4, 'learning_rate': 0.060139921974254246, 'subsample': 0.7540993071507188, 'colsample_bytree': 0.5428415447592839, 'gamma': 0.06366038016062041, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:02] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:02,819] Trial 97 finished with value: 0.6173361522198731 and parameters: {'n_estimators': 293, 'max_depth': 5, 'learning_rate': 0.07271389088507482, 'subsample': 0.7705672501815015, 'colsample_bytree': 0.6273647265953689, 'gamma': 0.29049540985012, 'min_child_weight': 5}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:02] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:03,018] Trial 98 finished with value: 0.6166328600405679 and parameters: {'n_estimators': 240, 'max_depth': 4, 'learning_rate': 0.08390066765651219, 'subsample': 0.8157164825458461, 'colsample_bytree': 0.656327451428062, 'gamma': 0.5035320980748861, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:03,217] Trial 99 finished with value: 0.625 and parameters: {'n_estimators': 231, 'max_depth': 5, 'learning_rate': 0.0402590570023334, 'subsample': 0.8820560243801493, 'colsample_bytree': 0.5099373090192665, 'gamma': 0.8078604153063595, 'min_child_weight': 4}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:03,430] Trial 100 finished with value: 0.618421052631579 and parameters: {'n_estimators': 275, 'max_depth': 5, 'learning_rate': 0.09148592627947004, 'subsample': 0.7974690242711514, 'colsample_bytree': 0.6050883086604869, 'gamma': 0.2740335528248554, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:03,571] Trial 101 finished with value: 0.602510460251046 and parameters: {'n_estimators': 295, 'max_depth': 5, 'learning_rate': 0.19590996994036497, 'subsample': 0.8379435652038748, 'colsample_bytree': 0.6795965657621905, 'gamma': 3.872463021655808, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:03,845] Trial 102 finished with value: 0.6313645621181263 and parameters: {'n_estimators': 284, 'max_depth': 4, 'learning_rate': 0.06463703266338974, 'subsample': 0.8624648066180811, 'colsample_bytree': 0.5540603705310984, 'gamma': 4.082936080125784, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:04,142] Trial 103 finished with value: 0.6232179226069247 and parameters: {'n_estimators': 285, 'max_depth': 4, 'learning_rate': 0.06573858546653358, 'subsample': 0.8559215111441768, 'colsample_bytree': 0.5333656127256197, 'gamma': 0.12471776051531147, 'min_child_weight': 3}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:04] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:04,416] Trial 104 finished with value: 0.623015873015873 and parameters: {'n_estimators': 265, 'max_depth': 3, 'learning_rate': 0.057024503304037584, 'subsample': 0.8288455147842287, 'colsample_bytree': 0.5566861448176383, 'gamma': 4.080410422789373, 'min_child_weight': 4}. Best is trial 16 with value: 0.6369426751592356.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:04] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:04,582] Trial 105 finished with value: 0.6374501992031872 and parameters: {'n_estimators': 270, 'max_depth': 4, 'learning_rate': 0.07793304826814272, 'subsample': 0.7843344373896282, 'colsample_bytree': 0.5002366389234395, 'gamma': 4.319595179841944, 'min_child_weight': 3}. Best is trial 105 with value: 0.6374501992031872.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:04] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:04,767] Trial 106 finished with value: 0.6265060240963856 and parameters: {'n_estimators': 278, 'max_depth': 4, 'learning_rate': 0.0809365619242463, 'subsample': 0.9068953943394021, 'colsample_bytree': 0.5100892160577664, 'gamma': 4.295357456258852, 'min_child_weight': 3}. Best is trial 105 with value: 0.6374501992031872.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:04] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:04,979] Trial 107 finished with value: 0.6172344689378757 and parameters: {'n_estimators': 271, 'max_depth': 4, 'learning_rate': 0.05061017514537436, 'subsample': 0.8433465099927838, 'colsample_bytree': 0.5694537626332407, 'gamma': 4.070200332262217, 'min_child_weight': 2}. Best is trial 105 with value: 0.6374501992031872.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:05] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:05,264] Trial 108 finished with value: 0.6196078431372549 and parameters: {'n_estimators': 259, 'max_depth': 3, 'learning_rate': 0.03182416149303183, 'subsample': 0.515030298077948, 'colsample_bytree': 0.5020952222905554, 'gamma': 4.5036544149008595, 'min_child_weight': 4}. Best is trial 105 with value: 0.6374501992031872.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:05] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:05,453] Trial 109 finished with value: 0.625 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.1146277987291737, 'subsample': 0.7811555333692912, 'colsample_bytree': 0.5234511618789203, 'gamma': 4.770151069243757, 'min_child_weight': 3}. Best is trial 105 with value: 0.6374501992031872.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:05] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:05,686] Trial 110 finished with value: 0.6282306163021869 and parameters: {'n_estimators': 264, 'max_depth': 3, 'learning_rate': 0.05976772958237981, 'subsample': 0.7384109637569524, 'colsample_bytree': 0.9653723118673072, 'gamma': 4.363977401739691, 'min_child_weight': 2}. Best is trial 105 with value: 0.6374501992031872.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:05] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:05,899] Trial 111 finished with value: 0.6232179226069247 and parameters: {'n_estimators': 289, 'max_depth': 5, 'learning_rate': 0.07288919960945983, 'subsample': 0.8135950358538206, 'colsample_bytree': 0.6272005102998275, 'gamma': 4.217019787610751, 'min_child_weight': 3}. Best is trial 105 with value: 0.6374501992031872.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:05] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:06,085] Trial 112 finished with value: 0.6169354838709677 and parameters: {'n_estimators': 295, 'max_depth': 4, 'learning_rate': 0.08877813990625369, 'subsample': 0.883698452691758, 'colsample_bytree': 0.7207102050040528, 'gamma': 3.8667534892996573, 'min_child_weight': 3}. Best is trial 105 with value: 0.6374501992031872.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:06] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:06,336] Trial 113 finished with value: 0.6177105831533477 and parameters: {'n_estimators': 283, 'max_depth': 5, 'learning_rate': 0.09716143577477748, 'subsample': 0.7890856628040478, 'colsample_bytree': 0.5489922621516746, 'gamma': 0.33216808511699364, 'min_child_weight': 4}. Best is trial 105 with value: 0.6374501992031872.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:06] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:06,601] Trial 114 finished with value: 0.6137339055793991 and parameters: {'n_estimators': 276, 'max_depth': 6, 'learning_rate': 0.06957156091887898, 'subsample': 0.7629306571745501, 'colsample_bytree': 0.5356987094895681, 'gamma': 0.006884667000236983, 'min_child_weight': 3}. Best is trial 105 with value: 0.6374501992031872.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:06] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:06,795] Trial 115 finished with value: 0.6382113821138211 and parameters: {'n_estimators': 290, 'max_depth': 5, 'learning_rate': 0.07789310524829916, 'subsample': 0.8028236599783986, 'colsample_bytree': 0.6153909355321883, 'gamma': 4.571777416527809, 'min_child_weight': 2}. Best is trial 115 with value: 0.6382113821138211.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:06] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:06,994] Trial 116 finished with value: 0.6227544910179641 and parameters: {'n_estimators': 269, 'max_depth': 4, 'learning_rate': 0.04654209738994411, 'subsample': 0.8610693678559229, 'colsample_bytree': 0.5900897555300584, 'gamma': 4.972312728294273, 'min_child_weight': 2}. Best is trial 115 with value: 0.6382113821138211.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:07] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:07,209] Trial 117 finished with value: 0.6333333333333333 and parameters: {'n_estimators': 291, 'max_depth': 5, 'learning_rate': 0.06374427050080436, 'subsample': 0.8218142429552292, 'colsample_bytree': 0.5614108684761842, 'gamma': 4.160934461044525, 'min_child_weight': 2}. Best is trial 115 with value: 0.6382113821138211.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:07] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:07,392] Trial 118 finished with value: 0.614406779661017 and parameters: {'n_estimators': 296, 'max_depth': 6, 'learning_rate': 0.08435068272993282, 'subsample': 0.8223073961710323, 'colsample_bytree': 0.5618484799305385, 'gamma': 3.679799232741921, 'min_child_weight': 2}. Best is trial 115 with value: 0.6382113821138211.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:07] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:07,581] Trial 119 finished with value: 0.625 and parameters: {'n_estimators': 293, 'max_depth': 4, 'learning_rate': 0.06371599326768694, 'subsample': 0.805758506259643, 'colsample_bytree': 0.5008340633373247, 'gamma': 4.5814227795765365, 'min_child_weight': 2}. Best is trial 115 with value: 0.6382113821138211.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:07] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:07,754] Trial 120 finished with value: 0.6153846153846154 and parameters: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.07978718801241937, 'subsample': 0.8963723573725533, 'colsample_bytree': 0.5147033274415102, 'gamma': 3.955152994296256, 'min_child_weight': 2}. Best is trial 115 with value: 0.6382113821138211.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:07] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:07,958] Trial 121 finished with value: 0.6234817813765182 and parameters: {'n_estimators': 280, 'max_depth': 5, 'learning_rate': 0.05152193224700254, 'subsample': 0.8487788862332717, 'colsample_bytree': 0.5274966362971053, 'gamma': 4.128304125339044, 'min_child_weight': 3}. Best is trial 115 with value: 0.6382113821138211.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:07] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:08,147] Trial 122 finished with value: 0.621676891615542 and parameters: {'n_estimators': 272, 'max_depth': 5, 'learning_rate': 0.06693706659024286, 'subsample': 0.8337577571178943, 'colsample_bytree': 0.9370296432132075, 'gamma': 4.2784873327289095, 'min_child_weight': 2}. Best is trial 115 with value: 0.6382113821138211.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:08] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:08,479] Trial 123 finished with value: 0.6103092783505155 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05677613130377222, 'subsample': 0.5557404590478194, 'colsample_bytree': 0.5794033579978378, 'gamma': 4.70444035341124, 'min_child_weight': 3}. Best is trial 115 with value: 0.6382113821138211.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:08] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:08,779] Trial 124 finished with value: 0.6398305084745762 and parameters: {'n_estimators': 284, 'max_depth': 6, 'learning_rate': 0.04155462053710831, 'subsample': 0.7762560378019867, 'colsample_bytree': 0.9196657869222666, 'gamma': 4.36925049361824, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:08] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:09,092] Trial 125 finished with value: 0.6376811594202898 and parameters: {'n_estimators': 291, 'max_depth': 6, 'learning_rate': 0.04143342351073789, 'subsample': 0.7805716380825959, 'colsample_bytree': 0.9150446592581242, 'gamma': 4.534401068045916, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:09] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:09,390] Trial 126 finished with value: 0.6276150627615062 and parameters: {'n_estimators': 291, 'max_depth': 6, 'learning_rate': 0.04070570883956019, 'subsample': 0.7743194558097576, 'colsample_bytree': 0.9155683675972064, 'gamma': 4.548873361494859, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:09] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:09,587] Trial 127 finished with value: 0.6255144032921811 and parameters: {'n_estimators': 130, 'max_depth': 6, 'learning_rate': 0.03029117611673455, 'subsample': 0.7987546434790074, 'colsample_bytree': 0.8977252151242503, 'gamma': 4.340494018043007, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:09] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:09,892] Trial 128 finished with value: 0.6192468619246861 and parameters: {'n_estimators': 285, 'max_depth': 6, 'learning_rate': 0.03698312844336961, 'subsample': 0.7788124712570558, 'colsample_bytree': 0.9216786932416002, 'gamma': 4.176957282956943, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:09] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:10,025] Trial 129 finished with value: 0.6189473684210526 and parameters: {'n_estimators': 277, 'max_depth': 6, 'learning_rate': 0.14958881277308905, 'subsample': 0.9147746366285096, 'colsample_bytree': 0.9024896906878696, 'gamma': 4.392722944665706, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:10] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:10,427] Trial 130 finished with value: 0.6229508196721312 and parameters: {'n_estimators': 292, 'max_depth': 6, 'learning_rate': 0.015639267299928834, 'subsample': 0.8666345212655571, 'colsample_bytree': 0.8803380372501978, 'gamma': 4.075358785876608, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:10] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:11,358] Trial 131 finished with value: 0.6229508196721312 and parameters: {'n_estimators': 282, 'max_depth': 6, 'learning_rate': 0.02128544020932875, 'subsample': 0.8092401299310356, 'colsample_bytree': 0.6431961183089414, 'gamma': 3.824385049200058, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:11] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:11,513] Trial 132 finished with value: 0.6111111111111112 and parameters: {'n_estimators': 296, 'max_depth': 3, 'learning_rate': 0.07090319022268875, 'subsample': 0.7660549578365047, 'colsample_bytree': 0.9092745890350685, 'gamma': 2.5035087786432757, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:11] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:11,725] Trial 133 finished with value: 0.6197183098591549 and parameters: {'n_estimators': 288, 'max_depth': 4, 'learning_rate': 0.04725065688335536, 'subsample': 0.8259597775647496, 'colsample_bytree': 0.9312716780475746, 'gamma': 4.615209814538185, 'min_child_weight': 3}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:11] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:11,884] Trial 134 finished with value: 0.6160337552742616 and parameters: {'n_estimators': 270, 'max_depth': 5, 'learning_rate': 0.13231873362460878, 'subsample': 0.8171879425334045, 'colsample_bytree': 0.865914098677288, 'gamma': 4.243316126535518, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:11] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:12,163] Trial 135 finished with value: 0.6053811659192825 and parameters: {'n_estimators': 275, 'max_depth': 10, 'learning_rate': 0.06244168649296545, 'subsample': 0.7530501569490629, 'colsample_bytree': 0.6686112672551976, 'gamma': 3.1298135651037757, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:12] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:12,535] Trial 136 finished with value: 0.6057906458797327 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.07927876940797993, 'subsample': 0.7934899554578223, 'colsample_bytree': 0.8933179971187872, 'gamma': 2.790519770885986, 'min_child_weight': 3}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:12] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:13,000] Trial 137 finished with value: 0.622680412371134 and parameters: {'n_estimators': 284, 'max_depth': 6, 'learning_rate': 0.05595903343418682, 'subsample': 0.8019003931693978, 'colsample_bytree': 0.5885052525866846, 'gamma': 4.851343100842031, 'min_child_weight': 3}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:13] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:13,208] Trial 138 finished with value: 0.6135458167330677 and parameters: {'n_estimators': 290, 'max_depth': 4, 'learning_rate': 0.09622795798499367, 'subsample': 0.8777210909798706, 'colsample_bytree': 0.9425127236882556, 'gamma': 4.455921329887165, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:13] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:13,543] Trial 139 finished with value: 0.6263498920086393 and parameters: {'n_estimators': 262, 'max_depth': 9, 'learning_rate': 0.026669335748323905, 'subsample': 0.8435028683014314, 'colsample_bytree': 0.5594798746946041, 'gamma': 3.9521364673122688, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:13] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:13,736] Trial 140 finished with value: 0.6247464503042597 and parameters: {'n_estimators': 280, 'max_depth': 5, 'learning_rate': 0.0408849991454335, 'subsample': 0.8554826890343951, 'colsample_bytree': 0.6040298373486381, 'gamma': 3.7372036589223594, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:13] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:13,932] Trial 141 finished with value: 0.6260162601626016 and parameters: {'n_estimators': 267, 'max_depth': 5, 'learning_rate': 0.0541447006992812, 'subsample': 0.7238499424010065, 'colsample_bytree': 0.9563425046877675, 'gamma': 4.429960920923805, 'min_child_weight': 9}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:13] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:14,126] Trial 142 finished with value: 0.6326530612244898 and parameters: {'n_estimators': 279, 'max_depth': 5, 'learning_rate': 0.07434600616373443, 'subsample': 0.7838959679893995, 'colsample_bytree': 0.9191865423908392, 'gamma': 4.01115134456672, 'min_child_weight': 3}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:14] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:14,327] Trial 143 finished with value: 0.625 and parameters: {'n_estimators': 274, 'max_depth': 5, 'learning_rate': 0.07619658829486539, 'subsample': 0.7855367668278906, 'colsample_bytree': 0.9192124684634707, 'gamma': 4.01051403435336, 'min_child_weight': 3}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:14] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:14,574] Trial 144 finished with value: 0.6118143459915611 and parameters: {'n_estimators': 295, 'max_depth': 6, 'learning_rate': 0.0686023822364784, 'subsample': 0.7722883411459597, 'colsample_bytree': 0.9299828449975839, 'gamma': 3.5618311726528558, 'min_child_weight': 3}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:14] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:14,723] Trial 145 finished with value: 0.6234817813765182 and parameters: {'n_estimators': 257, 'max_depth': 4, 'learning_rate': 0.08859596659101676, 'subsample': 0.8167117317884197, 'colsample_bytree': 0.8096831185833611, 'gamma': 4.0992301285892125, 'min_child_weight': 4}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:14] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:14,945] Trial 146 finished with value: 0.6097560975609756 and parameters: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.06319459188678463, 'subsample': 0.795376166384566, 'colsample_bytree': 0.9114170441306156, 'gamma': 4.169058347013432, 'min_child_weight': 8}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:14] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:15,105] Trial 147 finished with value: 0.6187624750499002 and parameters: {'n_estimators': 279, 'max_depth': 4, 'learning_rate': 0.0837415076592924, 'subsample': 0.8335426036445899, 'colsample_bytree': 0.7249447331546429, 'gamma': 2.9081472530165633, 'min_child_weight': 3}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:15,355] Trial 148 finished with value: 0.6088794926004228 and parameters: {'n_estimators': 291, 'max_depth': 6, 'learning_rate': 0.07193015228508567, 'subsample': 0.8085665099898469, 'colsample_bytree': 0.886052162748555, 'gamma': 3.833906701612719, 'min_child_weight': 3}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:15,431] Trial 149 finished with value: 0.608 and parameters: {'n_estimators': 51, 'max_depth': 5, 'learning_rate': 0.05806320683136542, 'subsample': 0.7836383383182939, 'colsample_bytree': 0.9019602973575135, 'gamma': 4.320720802129161, 'min_child_weight': 3}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:15,548] Trial 150 finished with value: 0.6334661354581673 and parameters: {'n_estimators': 212, 'max_depth': 3, 'learning_rate': 0.07668636931010214, 'subsample': 0.8965088108021448, 'colsample_bytree': 0.5373192715587225, 'gamma': 3.9416291402339967, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:15,680] Trial 151 finished with value: 0.6349206349206349 and parameters: {'n_estimators': 204, 'max_depth': 3, 'learning_rate': 0.07622595884299596, 'subsample': 0.8858726497348678, 'colsample_bytree': 0.5420742256487541, 'gamma': 3.928257426535197, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:15,785] Trial 152 finished with value: 0.628 and parameters: {'n_estimators': 197, 'max_depth': 3, 'learning_rate': 0.0789811196949406, 'subsample': 0.8986508552428669, 'colsample_bytree': 0.5364374080242067, 'gamma': 3.9629953548571533, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:15,890] Trial 153 finished with value: 0.6387225548902196 and parameters: {'n_estimators': 210, 'max_depth': 3, 'learning_rate': 0.06619565285196657, 'subsample': 0.8833075126988225, 'colsample_bytree': 0.5504764308605105, 'gamma': 3.6733923355136513, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:15,988] Trial 154 finished with value: 0.6374501992031872 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.08642148070982461, 'subsample': 0.8801827184994513, 'colsample_bytree': 0.505361116713644, 'gamma': 3.6505824389927994, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:16] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:16,093] Trial 155 finished with value: 0.6345381526104418 and parameters: {'n_estimators': 204, 'max_depth': 3, 'learning_rate': 0.08567272902769489, 'subsample': 0.8857227168141203, 'colsample_bytree': 0.5122759668659627, 'gamma': 3.6694895189092014, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:16] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:16,200] Trial 156 finished with value: 0.628 and parameters: {'n_estimators': 210, 'max_depth': 3, 'learning_rate': 0.101938847438447, 'subsample': 0.8903662381939451, 'colsample_bytree': 0.5203903008623617, 'gamma': 3.4065858947217236, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:16] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:16,296] Trial 157 finished with value: 0.6282306163021869 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.0829909092296348, 'subsample': 0.91114738417889, 'colsample_bytree': 0.5074434799302849, 'gamma': 3.6317255831025435, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:16] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:16,404] Trial 158 finished with value: 0.625250501002004 and parameters: {'n_estimators': 216, 'max_depth': 3, 'learning_rate': 0.09225805448321592, 'subsample': 0.9315443200657658, 'colsample_bytree': 0.5190977600482347, 'gamma': 3.680312114060759, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:16] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:16,528] Trial 159 finished with value: 0.6234817813765182 and parameters: {'n_estimators': 211, 'max_depth': 3, 'learning_rate': 0.10996793422855505, 'subsample': 0.8867670320191687, 'colsample_bytree': 0.5451992689846549, 'gamma': 3.5229624051704853, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:16] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:16,672] Trial 160 finished with value: 0.6275303643724697 and parameters: {'n_estimators': 207, 'max_depth': 3, 'learning_rate': 0.08772319444633161, 'subsample': 0.8998937268387179, 'colsample_bytree': 0.5003739798831165, 'gamma': 3.31915574220084, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:16] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:16,816] Trial 161 finished with value: 0.6254980079681275 and parameters: {'n_estimators': 226, 'max_depth': 3, 'learning_rate': 0.06748225837637221, 'subsample': 0.8769425467885842, 'colsample_bytree': 0.524752811094199, 'gamma': 3.885707599656544, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:16] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:16,972] Trial 162 finished with value: 0.6242544731610338 and parameters: {'n_estimators': 194, 'max_depth': 3, 'learning_rate': 0.07229461369920745, 'subsample': 0.8847574915256013, 'colsample_bytree': 0.5341632791834129, 'gamma': 3.7505654823976236, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:17] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:17,092] Trial 163 finished with value: 0.6336633663366337 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.04439468845474286, 'subsample': 0.8728759847013527, 'colsample_bytree': 0.5162636947434386, 'gamma': 3.8344556992879903, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:17] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:17,224] Trial 164 finished with value: 0.6223091976516634 and parameters: {'n_estimators': 222, 'max_depth': 3, 'learning_rate': 0.035402791983027676, 'subsample': 0.8701591973627965, 'colsample_bytree': 0.5125374998271452, 'gamma': 3.569970586760115, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:17] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:17,347] Trial 165 finished with value: 0.626746506986028 and parameters: {'n_estimators': 201, 'max_depth': 3, 'learning_rate': 0.045437875131881515, 'subsample': 0.9186708053997483, 'colsample_bytree': 0.5667774197490407, 'gamma': 3.7995913709226667, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:17] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:17,472] Trial 166 finished with value: 0.6141732283464567 and parameters: {'n_estimators': 187, 'max_depth': 3, 'learning_rate': 0.052823486481149984, 'subsample': 0.8927466655824134, 'colsample_bytree': 0.5265816247864358, 'gamma': 3.695830916485397, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:17] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:17,603] Trial 167 finished with value: 0.6297029702970297 and parameters: {'n_estimators': 203, 'max_depth': 3, 'learning_rate': 0.059768738176629296, 'subsample': 0.8775545633358239, 'colsample_bytree': 0.5423950081261963, 'gamma': 3.871537440935209, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:17] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:17,772] Trial 168 finished with value: 0.6284584980237155 and parameters: {'n_estimators': 212, 'max_depth': 3, 'learning_rate': 0.09587871292337942, 'subsample': 0.9062526797200955, 'colsample_bytree': 0.517490246848389, 'gamma': 3.448556869771925, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:17] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:17,932] Trial 169 finished with value: 0.631163708086785 and parameters: {'n_estimators': 217, 'max_depth': 3, 'learning_rate': 0.048818247692671415, 'subsample': 0.8680434693762477, 'colsample_bytree': 0.5119004243494687, 'gamma': 4.2314222419361815, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:17] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:18,100] Trial 170 finished with value: 0.6197183098591549 and parameters: {'n_estimators': 207, 'max_depth': 3, 'learning_rate': 0.17096677148408843, 'subsample': 0.8912832388150651, 'colsample_bytree': 0.530320376409186, 'gamma': 3.620517227935473, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:18,234] Trial 171 finished with value: 0.6361829025844931 and parameters: {'n_estimators': 197, 'max_depth': 3, 'learning_rate': 0.07809657822284564, 'subsample': 0.8590152315477014, 'colsample_bytree': 0.5537285586129601, 'gamma': 4.122445943316309, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:18,377] Trial 172 finished with value: 0.624 and parameters: {'n_estimators': 195, 'max_depth': 3, 'learning_rate': 0.08262900568561513, 'subsample': 0.863491746281887, 'colsample_bytree': 0.5493657686063557, 'gamma': 4.042752759452596, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:18,512] Trial 173 finished with value: 0.632 and parameters: {'n_estimators': 220, 'max_depth': 3, 'learning_rate': 0.08609758694350897, 'subsample': 0.8531889756829906, 'colsample_bytree': 0.5007836151104224, 'gamma': 4.135895423190573, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:18,632] Trial 174 finished with value: 0.6245059288537549 and parameters: {'n_estimators': 189, 'max_depth': 3, 'learning_rate': 0.0430955794358788, 'subsample': 0.8766955293846084, 'colsample_bytree': 0.5366059878566937, 'gamma': 3.823865019162822, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:18,841] Trial 175 finished with value: 0.6345381526104418 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.07992154161464861, 'subsample': 0.8839156525457005, 'colsample_bytree': 0.5516731305660181, 'gamma': 4.658056654328464, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:19,078] Trial 176 finished with value: 0.6138613861386139 and parameters: {'n_estimators': 180, 'max_depth': 3, 'learning_rate': 0.18004289092006123, 'subsample': 0.9024237051955408, 'colsample_bytree': 0.7874332604347237, 'gamma': 4.743545472842153, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:19] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:19,259] Trial 177 finished with value: 0.6277665995975855 and parameters: {'n_estimators': 199, 'max_depth': 3, 'learning_rate': 0.09169318230643284, 'subsample': 0.8883469589384025, 'colsample_bytree': 0.5534752950235606, 'gamma': 4.639468398204847, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:19] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:19,439] Trial 178 finished with value: 0.6254980079681275 and parameters: {'n_estimators': 204, 'max_depth': 3, 'learning_rate': 0.07931152937369418, 'subsample': 0.9424189065267818, 'colsample_bytree': 0.512406858145901, 'gamma': 4.347614892533371, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:19] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:19,622] Trial 179 finished with value: 0.6227544910179641 and parameters: {'n_estimators': 211, 'max_depth': 3, 'learning_rate': 0.06960173253568747, 'subsample': 0.878200806859774, 'colsample_bytree': 0.5285796582956699, 'gamma': 4.591077209562304, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:19] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:19,730] Trial 180 finished with value: 0.6123260437375746 and parameters: {'n_estimators': 195, 'max_depth': 3, 'learning_rate': 0.15886734443809886, 'subsample': 0.9107881911583684, 'colsample_bytree': 0.5408916878980627, 'gamma': 4.501403521977601, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:19] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:19,896] Trial 181 finished with value: 0.6090534979423868 and parameters: {'n_estimators': 205, 'max_depth': 6, 'learning_rate': 0.06446098660190924, 'subsample': 0.8607506240436421, 'colsample_bytree': 0.5565222659313059, 'gamma': 4.238148969359328, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:19] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:20,029] Trial 182 finished with value: 0.6245059288537549 and parameters: {'n_estimators': 208, 'max_depth': 3, 'learning_rate': 0.07709671448875571, 'subsample': 0.8692918876095722, 'colsample_bytree': 0.5719698866685021, 'gamma': 3.970547641958202, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:20] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:20,164] Trial 183 finished with value: 0.626984126984127 and parameters: {'n_estimators': 214, 'max_depth': 3, 'learning_rate': 0.05893986630061282, 'subsample': 0.8494770525623382, 'colsample_bytree': 0.5157462779824014, 'gamma': 4.155292854891178, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:20] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:20,321] Trial 184 finished with value: 0.6172839506172839 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.0853932689701925, 'subsample': 0.8853876099034171, 'colsample_bytree': 0.528263167237534, 'gamma': 3.7752540597492312, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:20] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:20,453] Trial 185 finished with value: 0.6254980079681275 and parameters: {'n_estimators': 168, 'max_depth': 3, 'learning_rate': 0.06762996681231002, 'subsample': 0.8982006041574605, 'colsample_bytree': 0.5637915402126908, 'gamma': 4.393722128357589, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:20] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:20,730] Trial 186 finished with value: 0.6302521008403361 and parameters: {'n_estimators': 147, 'max_depth': 6, 'learning_rate': 0.07688346806215082, 'subsample': 0.8735516734768404, 'colsample_bytree': 0.5783069742762185, 'gamma': 1.468205651163569, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:20] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:20,845] Trial 187 finished with value: 0.6242544731610338 and parameters: {'n_estimators': 183, 'max_depth': 3, 'learning_rate': 0.05008842398902784, 'subsample': 0.8575691018376616, 'colsample_bytree': 0.5460236866082238, 'gamma': 3.9224681747397927, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:20] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:20,979] Trial 188 finished with value: 0.6302521008403361 and parameters: {'n_estimators': 193, 'max_depth': 7, 'learning_rate': 0.14086494002843328, 'subsample': 0.8824367099313761, 'colsample_bytree': 0.508231606832834, 'gamma': 4.473099590756877, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:21] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:21,073] Trial 189 finished with value: 0.6147704590818364 and parameters: {'n_estimators': 97, 'max_depth': 4, 'learning_rate': 0.03890355020108545, 'subsample': 0.893636776855754, 'colsample_bytree': 0.5194010590266692, 'gamma': 4.839650069239969, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:21] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:21,197] Trial 190 finished with value: 0.5921052631578947 and parameters: {'n_estimators': 230, 'max_depth': 12, 'learning_rate': 0.2717629830932705, 'subsample': 0.9253627750150007, 'colsample_bytree': 0.5000627874419132, 'gamma': 4.046633443588701, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:21] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:21,410] Trial 191 finished with value: 0.6166666666666667 and parameters: {'n_estimators': 296, 'max_depth': 5, 'learning_rate': 0.07262372544061613, 'subsample': 0.7774387113618049, 'colsample_bytree': 0.9403087828523272, 'gamma': 4.023614495762986, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:21] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:22,004] Trial 192 finished with value: 0.6268041237113402 and parameters: {'n_estimators': 199, 'max_depth': 5, 'learning_rate': 0.07533256983746789, 'subsample': 0.7661030514608045, 'colsample_bytree': 0.9137963946355373, 'gamma': 4.27878183527311, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:22] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:22,189] Trial 193 finished with value: 0.6101694915254238 and parameters: {'n_estimators': 289, 'max_depth': 6, 'learning_rate': 0.08178483124511923, 'subsample': 0.7921296334243064, 'colsample_bytree': 0.9239901724262743, 'gamma': 3.920060294064426, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:22] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:22,352] Trial 194 finished with value: 0.6326530612244898 and parameters: {'n_estimators': 216, 'max_depth': 5, 'learning_rate': 0.062434995449338525, 'subsample': 0.8671997540603008, 'colsample_bytree': 0.535502102348537, 'gamma': 3.6878926724391916, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:22] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:22,518] Trial 195 finished with value: 0.6242544731610338 and parameters: {'n_estimators': 205, 'max_depth': 3, 'learning_rate': 0.0700833870366556, 'subsample': 0.7850496743376477, 'colsample_bytree': 0.8941191461156281, 'gamma': 4.134123850255977, 'min_child_weight': 1}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:22] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:22,685] Trial 196 finished with value: 0.6324435318275154 and parameters: {'n_estimators': 188, 'max_depth': 6, 'learning_rate': 0.05560269516219024, 'subsample': 0.8007510962613393, 'colsample_bytree': 0.5476595198201099, 'gamma': 3.8276926923916057, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:22] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:22,839] Trial 197 finished with value: 0.631163708086785 and parameters: {'n_estimators': 221, 'max_depth': 3, 'learning_rate': 0.0853590722545199, 'subsample': 0.7544370749307184, 'colsample_bytree': 0.903924343410529, 'gamma': 1.1474258810456215, 'min_child_weight': 6}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:22] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:23,036] Trial 198 finished with value: 0.6078028747433265 and parameters: {'n_estimators': 293, 'max_depth': 5, 'learning_rate': 0.09050629545741266, 'subsample': 0.8470554285118703, 'colsample_bytree': 0.7398444758314262, 'gamma': 4.055496215505632, 'min_child_weight': 2}. Best is trial 124 with value: 0.6398305084745762.\n",
      "/home/over-mind/Downloads/end-to-end-churn-project/env/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [17:09:23] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-11-27 17:09:23,164] Trial 199 finished with value: 0.632 and parameters: {'n_estimators': 212, 'max_depth': 4, 'learning_rate': 0.0738622637087624, 'subsample': 0.9019203639294016, 'colsample_bytree': 0.523367170414822, 'gamma': 4.5331868413791945, 'min_child_weight': 3}. Best is trial 124 with value: 0.6398305084745762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 Score: 0.6398305084745762\n",
      "Best Hyperparameters: {'n_estimators': 284, 'max_depth': 6, 'learning_rate': 0.04155462053710831, 'subsample': 0.7762560378019867, 'colsample_bytree': 0.9196657869222666, 'gamma': 4.36925049361824, 'min_child_weight': 2}\n"
     ]
    }
   ],
   "source": [
    "# Create and run study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(xgb_objective, n_trials=200, show_progress_bar=False)\n",
    "# Best results\n",
    "print(\"Best F1 Score:\", study.best_value)\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "xgb_best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2b59cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       796\n",
      "           1       0.74      0.47      0.58       204\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.81      0.71      0.75      1000\n",
      "weighted avg       0.85      0.86      0.85      1000\n",
      "\n",
      "f1  0.5765765765765766\n",
      "===========================================================\n",
      "Classification Report for Training Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      7167\n",
      "           1       0.81      0.52      0.64      1833\n",
      "\n",
      "    accuracy                           0.88      9000\n",
      "   macro avg       0.85      0.75      0.78      9000\n",
      "weighted avg       0.87      0.88      0.87      9000\n",
      "\n",
      "f1  0.6356382978723404\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(**xgb_best_params)\n",
    "xgb_model.fit(X_train_processed, y_train)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_processed)\n",
    "print(\"Classification Report for Test Set:\\n\", classification_report(y_test, y_test_pred_xgb))\n",
    "print('f1 ', f1_score(y_test, y_test_pred_xgb))\n",
    "print('===========================================================')\n",
    "y_train_pred_xgb = xgb_model.predict(X_train_processed)\n",
    "print(\"Classification Report for Training Set:\\n\", classification_report(y_train, y_train_pred_xgb))\n",
    "print('f1 ', f1_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922df054",
   "metadata": {},
   "source": [
    "# SHAP feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fcb022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=preprocessor.get_feature_names_out().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7301dd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|=================== | 8597/9000 [00:19<00:00]       "
     ]
    }
   ],
   "source": [
    "explainer = shap.Explainer(xgb_model, X_train_processed)\n",
    "shap_values = explainer(X_train_processed)\n",
    "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "# Create DF\n",
    "shap_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'SHAP_Value': mean_abs_shap\n",
    "}).sort_values(by='SHAP_Value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "858ff219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Feature</th>\n",
       "      <th>SHAP_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>num__Age</td>\n",
       "      <td>0.656855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>ready__NumOfProducts</td>\n",
       "      <td>0.382759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>ready__IsActiveMember</td>\n",
       "      <td>0.312855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>cat__Gender_Male</td>\n",
       "      <td>0.205226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>num__AgeProduct</td>\n",
       "      <td>0.202391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>cat__Geography_Germany</td>\n",
       "      <td>0.148347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>num__Balance</td>\n",
       "      <td>0.117916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>num__LogBalanceSalaryRatio</td>\n",
       "      <td>0.112232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>cat__AgeGroup_Senior</td>\n",
       "      <td>0.089163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>ready__ActivityScore</td>\n",
       "      <td>0.087921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>num__CreditScore</td>\n",
       "      <td>0.039928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>num__CLV</td>\n",
       "      <td>0.036352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>num__CustomerValue</td>\n",
       "      <td>0.031718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>ready__IsZeroBalance</td>\n",
       "      <td>0.030608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>num__EstimatedSalary</td>\n",
       "      <td>0.029925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>num__Tenure</td>\n",
       "      <td>0.014335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>ready__HasCrCard</td>\n",
       "      <td>0.009649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>cat__Geography_Spain</td>\n",
       "      <td>0.009619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22</td>\n",
       "      <td>ready__HighBalance</td>\n",
       "      <td>0.002695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12</td>\n",
       "      <td>cat__AgeGroup_Elderly</td>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15</td>\n",
       "      <td>cat__CreditTier_prime</td>\n",
       "      <td>0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14</td>\n",
       "      <td>cat__AgeGroup_Young</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16</td>\n",
       "      <td>cat__CreditTier_subprime</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17</td>\n",
       "      <td>cat__CreditTier_superprime</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                     Feature  SHAP_Value\n",
       "0       2                    num__Age    0.656855\n",
       "1      20        ready__NumOfProducts    0.382759\n",
       "2      21       ready__IsActiveMember    0.312855\n",
       "3      11            cat__Gender_Male    0.205226\n",
       "4       7             num__AgeProduct    0.202391\n",
       "5       9      cat__Geography_Germany    0.148347\n",
       "6       3                num__Balance    0.117916\n",
       "7       5  num__LogBalanceSalaryRatio    0.112232\n",
       "8      13        cat__AgeGroup_Senior    0.089163\n",
       "9      23        ready__ActivityScore    0.087921\n",
       "10      0            num__CreditScore    0.039928\n",
       "11      8                    num__CLV    0.036352\n",
       "12      6          num__CustomerValue    0.031718\n",
       "13     19        ready__IsZeroBalance    0.030608\n",
       "14      4        num__EstimatedSalary    0.029925\n",
       "15      1                 num__Tenure    0.014335\n",
       "16     18            ready__HasCrCard    0.009649\n",
       "17     10        cat__Geography_Spain    0.009619\n",
       "18     22          ready__HighBalance    0.002695\n",
       "19     12       cat__AgeGroup_Elderly    0.002118\n",
       "20     15       cat__CreditTier_prime    0.001565\n",
       "21     14         cat__AgeGroup_Young    0.000911\n",
       "22     16    cat__CreditTier_subprime    0.000000\n",
       "23     17  cat__CreditTier_superprime    0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_df_xgb=shap_df.reset_index()\n",
    "shap_df_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85ffe5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      num__Age\n",
       "1          ready__NumOfProducts\n",
       "2         ready__IsActiveMember\n",
       "3              cat__Gender_Male\n",
       "4               num__AgeProduct\n",
       "5        cat__Geography_Germany\n",
       "6                  num__Balance\n",
       "7    num__LogBalanceSalaryRatio\n",
       "8          cat__AgeGroup_Senior\n",
       "9          ready__ActivityScore\n",
       "Name: Feature, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_df_xgb['Feature'][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c3271c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = shap_df_xgb['Feature'][:11].tolist()\n",
    "top_feature_indices = [feature_names.index(feat) for feat in top_features]\n",
    "X_train_top = X_train_processed[:, top_feature_indices]\n",
    "X_test_top = X_test_processed[:, top_feature_indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b9e41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       796\n",
      "           1       0.72      0.47      0.57       204\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.80      0.71      0.74      1000\n",
      "weighted avg       0.84      0.85      0.84      1000\n",
      "\n",
      "f1  0.56973293768546\n",
      "Classification Report for train:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      7167\n",
      "           1       0.81      0.51      0.63      1833\n",
      "\n",
      "    accuracy                           0.88      9000\n",
      "   macro avg       0.85      0.74      0.78      9000\n",
      "weighted avg       0.87      0.88      0.86      9000\n",
      "\n",
      "f1  0.6263772954924874\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "# xgboost model with class weights\n",
    "final_xgb_model = xgb.XGBClassifier(**xgb_best_params)\n",
    "final_xgb_model.fit(X_train_top, y_train)\n",
    "y_test_pred_xgb = final_xgb_model.predict(X_test_top)\n",
    "print(\"Classification Report for test:\\n\", classification_report(y_test, y_test_pred_xgb))    \n",
    "print('f1 ', f1_score(y_test, y_test_pred_xgb))\n",
    "y_train_pred_xgb = final_xgb_model.predict(X_train_top)\n",
    "print(\"Classification Report for train:\\n\", classification_report(y_train, y_train_pred_xgb))\n",
    "print('f1 ', f1_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2d68c",
   "metadata": {},
   "source": [
    "# threshold tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70e205ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.30999999999999994 Best F1: 0.6350710900473934\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probs = final_xgb_model.predict_proba(X_test_top)[:,1]\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for thresh in np.arange(0.1, 0.9, 0.01):\n",
    "    preds = (probs > thresh).astype(int)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(\"Best threshold:\", best_thresh, \"Best F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef5d3e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       796\n",
      "           1       0.61      0.66      0.64       204\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.76      0.78      0.77      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n",
      "f1  0.6350710900473934\n",
      "===========================================================\n",
      "Classification Report for train:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      7167\n",
      "           1       0.66      0.67      0.67      1833\n",
      "\n",
      "    accuracy                           0.86      9000\n",
      "   macro avg       0.79      0.79      0.79      9000\n",
      "weighted avg       0.86      0.86      0.86      9000\n",
      "\n",
      "f1  0.6655879180151025\n"
     ]
    }
   ],
   "source": [
    "probs = final_xgb_model.predict_proba(X_test_top)[:, 1]\n",
    "y_test_pred_xgb = (probs > best_thresh).astype(int)\n",
    "print(\"Classification Report for test:\\n\", classification_report(y_test, y_test_pred_xgb))    \n",
    "print('f1 ', f1_score(y_test, y_test_pred_xgb))\n",
    "print('===========================================================')\n",
    "y_train_pred_xgb = (final_xgb_model.predict_proba(X_train_top)[:, 1] > best_thresh).astype(int)\n",
    "print(\"Classification Report for train:\\n\", classification_report(y_train, y_train_pred_xgb))\n",
    "print('f1 ', f1_score(y_train, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a266d",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465e378e",
   "metadata": {},
   "source": [
    "# catboost model base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9226a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       796\n",
      "           1       0.77      0.48      0.59       204\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.82      0.72      0.75      1000\n",
      "weighted avg       0.86      0.86      0.85      1000\n",
      "\n",
      "f1 score for test 0.5878787878787879\n",
      "=====================================================\n",
      "Classification Report for train:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      7167\n",
      "           1       0.91      0.63      0.74      1833\n",
      "\n",
      "    accuracy                           0.91      9000\n",
      "   macro avg       0.91      0.80      0.84      9000\n",
      "weighted avg       0.91      0.91      0.90      9000\n",
      "\n",
      "f1 score for train 0.7404777275661717\n"
     ]
    }
   ],
   "source": [
    "cat_model = CatBoostClassifier(verbose=False)\n",
    "train_pool = Pool(X_train_processed, y_train)\n",
    "cat_model.fit(train_pool)\n",
    "\n",
    "y_test_pred_cat = cat_model.predict(X_test_processed)\n",
    "print(\"Classification Report for test:\\n\", classification_report(y_test, y_test_pred_cat)) \n",
    "print('f1 score for test',f1_score(y_test, y_test_pred_cat))\n",
    "print('=====================================================')\n",
    "y_train_pred_cat = cat_model.predict(X_train_processed)\n",
    "print(\"Classification Report for train:\\n\", classification_report(y_train, y_train_pred_cat))\n",
    "print('f1 score for train',f1_score(y_train, y_train_pred_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bbf8bb",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning for catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05376d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 200, 1200),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 10.0),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 10.0),\n",
    "\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.8, 5.0),\n",
    "\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"F1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "        \"random_seed\": 42,\n",
    "        \"use_best_model\": True\n",
    "    }\n",
    "\n",
    "    # Pool\n",
    "    train_pool = Pool(X_train_processed, y_train)\n",
    "    valid_pool = Pool(X_test_processed, y_test)\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=valid_pool,\n",
    "        early_stopping_rounds=70,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Predict on validation\n",
    "    preds = model.predict(valid_pool)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52691445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 17:09:46,470] A new study created in memory with name: no-name-a3936d17-d62b-452f-be59-d638397b3a03\n",
      "[I 2025-11-27 17:09:47,295] Trial 0 finished with value: 0.6455981941309256 and parameters: {'iterations': 553, 'depth': 7, 'learning_rate': 0.1686853285547124, 'l2_leaf_reg': 2.9384461318747035, 'bagging_temperature': 5.247520547274956, 'random_strength': 6.266451198560795, 'scale_pos_weight': 2.7226847909950838}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:47,756] Trial 1 finished with value: 0.6372549019607843 and parameters: {'iterations': 978, 'depth': 6, 'learning_rate': 0.15965444119856922, 'l2_leaf_reg': 5.104854802370285, 'bagging_temperature': 0.4633676925964336, 'random_strength': 2.777046007197401, 'scale_pos_weight': 2.2326365981758736}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:48,003] Trial 2 finished with value: 0.5670886075949367 and parameters: {'iterations': 270, 'depth': 4, 'learning_rate': 0.011026934808935577, 'l2_leaf_reg': 5.310690299569942, 'bagging_temperature': 7.267460719760547, 'random_strength': 9.778633163839, 'scale_pos_weight': 2.076288571968416}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:49,176] Trial 3 finished with value: 0.6211180124223602 and parameters: {'iterations': 1150, 'depth': 8, 'learning_rate': 0.02962430883535734, 'l2_leaf_reg': 9.55210163271205, 'bagging_temperature': 9.171998568531333, 'random_strength': 4.850108839810191, 'scale_pos_weight': 3.658541290701712}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:50,221] Trial 4 finished with value: 0.6374501992031872 and parameters: {'iterations': 852, 'depth': 5, 'learning_rate': 0.059851418242796994, 'l2_leaf_reg': 8.691614831746005, 'bagging_temperature': 4.607529965386396, 'random_strength': 3.4994691655175076, 'scale_pos_weight': 3.742310069914784}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:51,709] Trial 5 finished with value: 0.6217821782178218 and parameters: {'iterations': 618, 'depth': 10, 'learning_rate': 0.27119050996419114, 'l2_leaf_reg': 1.053648268107267, 'bagging_temperature': 3.8978011520359814, 'random_strength': 1.271950361230284, 'scale_pos_weight': 4.0932670625325125}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:52,032] Trial 6 finished with value: 0.5843478260869566 and parameters: {'iterations': 429, 'depth': 5, 'learning_rate': 0.11424827485863177, 'l2_leaf_reg': 6.315591517786628, 'bagging_temperature': 2.5608477543387966, 'random_strength': 7.574781633463545, 'scale_pos_weight': 4.495243931455805}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:53,102] Trial 7 finished with value: 0.6193181818181818 and parameters: {'iterations': 959, 'depth': 3, 'learning_rate': 0.18211087360423647, 'l2_leaf_reg': 9.818534614977127, 'bagging_temperature': 7.200434898186762, 'random_strength': 3.2687014748804177, 'scale_pos_weight': 1.0748380441733447}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:53,414] Trial 8 finished with value: 0.5986078886310905 and parameters: {'iterations': 550, 'depth': 7, 'learning_rate': 0.06798010673761774, 'l2_leaf_reg': 9.779372577537929, 'bagging_temperature': 0.005387926485426187, 'random_strength': 9.107391836574704, 'scale_pos_weight': 1.9990953607445947}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:53,833] Trial 9 finished with value: 0.582089552238806 and parameters: {'iterations': 1052, 'depth': 8, 'learning_rate': 0.04232887807382524, 'l2_leaf_reg': 1.9647040348275628, 'bagging_temperature': 7.048469546732877, 'random_strength': 9.662848299268353, 'scale_pos_weight': 3.144853852443484}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:55,319] Trial 10 finished with value: 0.5974499089253188 and parameters: {'iterations': 790, 'depth': 10, 'learning_rate': 0.24042086555672976, 'l2_leaf_reg': 2.7664977071800685, 'bagging_temperature': 2.667584031684463, 'random_strength': 6.719344418334202, 'scale_pos_weight': 4.941331693568592}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:55,976] Trial 11 finished with value: 0.6422413793103449 and parameters: {'iterations': 781, 'depth': 6, 'learning_rate': 0.11418074646582199, 'l2_leaf_reg': 7.517437893099077, 'bagging_temperature': 5.126363152974851, 'random_strength': 5.049765208627523, 'scale_pos_weight': 3.079997794076251}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:56,615] Trial 12 finished with value: 0.6383928571428571 and parameters: {'iterations': 694, 'depth': 7, 'learning_rate': 0.20014024784783543, 'l2_leaf_reg': 7.204742475118984, 'bagging_temperature': 6.018129612097682, 'random_strength': 6.03412434326964, 'scale_pos_weight': 2.820445046502266}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:57,263] Trial 13 finished with value: 0.6310904872389791 and parameters: {'iterations': 429, 'depth': 8, 'learning_rate': 0.11394641808166021, 'l2_leaf_reg': 3.4522334851708716, 'bagging_temperature': 5.512056468610196, 'random_strength': 4.938600669336843, 'scale_pos_weight': 2.73037240371015}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:57,576] Trial 14 finished with value: 0.5770925110132159 and parameters: {'iterations': 520, 'depth': 6, 'learning_rate': 0.1221944323781875, 'l2_leaf_reg': 4.102267227056304, 'bagging_temperature': 9.137807933690823, 'random_strength': 7.810272567946313, 'scale_pos_weight': 1.5271842241403533}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:58,451] Trial 15 finished with value: 0.6324786324786325 and parameters: {'iterations': 788, 'depth': 9, 'learning_rate': 0.21329599149541573, 'l2_leaf_reg': 0.04448360773211624, 'bagging_temperature': 3.400408254553196, 'random_strength': 5.743875477788082, 'scale_pos_weight': 3.2648085467034167}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:59,238] Trial 16 finished with value: 0.6422018348623854 and parameters: {'iterations': 237, 'depth': 5, 'learning_rate': 0.14405372987054685, 'l2_leaf_reg': 7.683727363056565, 'bagging_temperature': 1.8887711208825477, 'random_strength': 3.9528056027700034, 'scale_pos_weight': 2.45598452681456}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:09:59,910] Trial 17 finished with value: 0.6430062630480167 and parameters: {'iterations': 673, 'depth': 6, 'learning_rate': 0.08945476194661701, 'l2_leaf_reg': 6.2198238179491385, 'bagging_temperature': 6.086726893420099, 'random_strength': 1.1417598447123187, 'scale_pos_weight': 3.4111218287491707}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:10:00,525] Trial 18 finished with value: 0.6343434343434343 and parameters: {'iterations': 375, 'depth': 7, 'learning_rate': 0.08661128139775764, 'l2_leaf_reg': 4.224969786333097, 'bagging_temperature': 8.01328419152589, 'random_strength': 0.4998212721270682, 'scale_pos_weight': 3.7616610497035756}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:10:01,276] Trial 19 finished with value: 0.6370757180156658 and parameters: {'iterations': 652, 'depth': 4, 'learning_rate': 0.15847076361581597, 'l2_leaf_reg': 5.931746293659133, 'bagging_temperature': 6.265515168959781, 'random_strength': 1.9250608402008105, 'scale_pos_weight': 1.535746962638598}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:10:02,204] Trial 20 finished with value: 0.625 and parameters: {'iterations': 565, 'depth': 9, 'learning_rate': 0.2393698013258988, 'l2_leaf_reg': 2.350388460980191, 'bagging_temperature': 4.40825767894311, 'random_strength': 7.8143247997259415, 'scale_pos_weight': 3.3840295828184894}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:10:02,666] Trial 21 finished with value: 0.6425339366515838 and parameters: {'iterations': 758, 'depth': 6, 'learning_rate': 0.08194862989405788, 'l2_leaf_reg': 7.340022438415388, 'bagging_temperature': 5.162239416745074, 'random_strength': 0.14567012934716494, 'scale_pos_weight': 2.8381091620614645}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:10:03,268] Trial 22 finished with value: 0.6438356164383562 and parameters: {'iterations': 885, 'depth': 6, 'learning_rate': 0.08140103055613881, 'l2_leaf_reg': 6.4774514662185885, 'bagging_temperature': 6.105093265575604, 'random_strength': 0.4248170599570175, 'scale_pos_weight': 2.6495105711033635}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:10:03,797] Trial 23 finished with value: 0.639225181598063 and parameters: {'iterations': 895, 'depth': 7, 'learning_rate': 0.09410087394249844, 'l2_leaf_reg': 6.507315212955252, 'bagging_temperature': 8.12005241808709, 'random_strength': 2.0264515177060898, 'scale_pos_weight': 2.508564432169524}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:10:04,234] Trial 24 finished with value: 0.6285714285714286 and parameters: {'iterations': 672, 'depth': 5, 'learning_rate': 0.1397356588252163, 'l2_leaf_reg': 4.4897380550971455, 'bagging_temperature': 6.379071646428111, 'random_strength': 1.327198590546735, 'scale_pos_weight': 4.28588601261627}. Best is trial 0 with value: 0.6455981941309256.\n",
      "[I 2025-11-27 17:10:04,737] Trial 25 finished with value: 0.6531645569620254 and parameters: {'iterations': 481, 'depth': 4, 'learning_rate': 0.1756027063688639, 'l2_leaf_reg': 3.29416378826971, 'bagging_temperature': 9.962807876902371, 'random_strength': 0.9863844904102284, 'scale_pos_weight': 1.768056948918789}. Best is trial 25 with value: 0.6531645569620254.\n",
      "[I 2025-11-27 17:10:05,528] Trial 26 finished with value: 0.6456692913385826 and parameters: {'iterations': 332, 'depth': 3, 'learning_rate': 0.17733030461865196, 'l2_leaf_reg': 3.333262770920802, 'bagging_temperature': 9.798033848344271, 'random_strength': 2.491585484708119, 'scale_pos_weight': 1.5369921583180748}. Best is trial 25 with value: 0.6531645569620254.\n",
      "[I 2025-11-27 17:10:06,083] Trial 27 finished with value: 0.5740740740740741 and parameters: {'iterations': 319, 'depth': 3, 'learning_rate': 0.17777453430372656, 'l2_leaf_reg': 3.2692359090555736, 'bagging_temperature': 9.947835021386746, 'random_strength': 4.128503474438872, 'scale_pos_weight': 0.8104106815294183}. Best is trial 25 with value: 0.6531645569620254.\n",
      "[I 2025-11-27 17:10:06,658] Trial 28 finished with value: 0.6323907455012854 and parameters: {'iterations': 475, 'depth': 4, 'learning_rate': 0.2161552027161651, 'l2_leaf_reg': 1.5833968479654001, 'bagging_temperature': 9.856352564485471, 'random_strength': 2.4979532194880156, 'scale_pos_weight': 1.651114688862196}. Best is trial 25 with value: 0.6531645569620254.\n",
      "[I 2025-11-27 17:10:07,149] Trial 29 finished with value: 0.6347607052896725 and parameters: {'iterations': 339, 'depth': 3, 'learning_rate': 0.17706138897531112, 'l2_leaf_reg': 3.4367294483946615, 'bagging_temperature': 8.664618096846686, 'random_strength': 2.3783105884483553, 'scale_pos_weight': 1.8335523964908798}. Best is trial 25 with value: 0.6531645569620254.\n",
      "[I 2025-11-27 17:10:07,612] Trial 30 finished with value: 0.6201117318435754 and parameters: {'iterations': 214, 'depth': 4, 'learning_rate': 0.2953320508378352, 'l2_leaf_reg': 1.1551088726652265, 'bagging_temperature': 8.112237611660516, 'random_strength': 3.0752389215761893, 'scale_pos_weight': 1.2366336880201163}. Best is trial 25 with value: 0.6531645569620254.\n",
      "[I 2025-11-27 17:10:08,137] Trial 31 finished with value: 0.6363636363636364 and parameters: {'iterations': 468, 'depth': 3, 'learning_rate': 0.15228668348534075, 'l2_leaf_reg': 5.192032390856059, 'bagging_temperature': 9.201647861287332, 'random_strength': 0.6428116733444772, 'scale_pos_weight': 2.266469987158134}. Best is trial 25 with value: 0.6531645569620254.\n",
      "[I 2025-11-27 17:10:08,807] Trial 32 finished with value: 0.6587677725118484 and parameters: {'iterations': 370, 'depth': 4, 'learning_rate': 0.1963260630195328, 'l2_leaf_reg': 2.8323908374410904, 'bagging_temperature': 9.977992956012015, 'random_strength': 1.7752934081281324, 'scale_pos_weight': 2.1785428971810807}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:09,361] Trial 33 finished with value: 0.6504854368932039 and parameters: {'iterations': 287, 'depth': 4, 'learning_rate': 0.19209869389715306, 'l2_leaf_reg': 2.8949438064447133, 'bagging_temperature': 1.028547364311259, 'random_strength': 1.6713368754852704, 'scale_pos_weight': 2.1890794470595933}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:09,838] Trial 34 finished with value: 0.6409638554216868 and parameters: {'iterations': 286, 'depth': 4, 'learning_rate': 0.19486714775561248, 'l2_leaf_reg': 2.732888549317464, 'bagging_temperature': 1.1898789408090908, 'random_strength': 1.6928658824623073, 'scale_pos_weight': 2.1574255835248}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:10,358] Trial 35 finished with value: 0.6131805157593123 and parameters: {'iterations': 398, 'depth': 4, 'learning_rate': 0.22816057162451525, 'l2_leaf_reg': 3.5295156298317383, 'bagging_temperature': 9.46407553439091, 'random_strength': 0.9627952627151974, 'scale_pos_weight': 1.155202650755371}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:10,834] Trial 36 finished with value: 0.6395939086294417 and parameters: {'iterations': 288, 'depth': 3, 'learning_rate': 0.25106473234984783, 'l2_leaf_reg': 4.608010423594118, 'bagging_temperature': 8.585587569406472, 'random_strength': 2.6452019353250655, 'scale_pos_weight': 1.7870870611068903}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:11,324] Trial 37 finished with value: 0.6323185011709602 and parameters: {'iterations': 368, 'depth': 5, 'learning_rate': 0.19491500831587058, 'l2_leaf_reg': 2.252246260301771, 'bagging_temperature': 8.673543179732254, 'random_strength': 3.9151603659828167, 'scale_pos_weight': 2.3375201756505866}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:11,782] Trial 38 finished with value: 0.6270270270270271 and parameters: {'iterations': 204, 'depth': 4, 'learning_rate': 0.16668492179545735, 'l2_leaf_reg': 3.9252264905701755, 'bagging_temperature': 7.729103123456801, 'random_strength': 1.6388354717506708, 'scale_pos_weight': 1.4146963314518899}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:12,263] Trial 39 finished with value: 0.64 and parameters: {'iterations': 489, 'depth': 3, 'learning_rate': 0.20925100056812157, 'l2_leaf_reg': 0.4993132378100542, 'bagging_temperature': 9.576394052260241, 'random_strength': 2.218093008023419, 'scale_pos_weight': 1.9466675449346071}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:12,839] Trial 40 finished with value: 0.6435643564356436 and parameters: {'iterations': 326, 'depth': 5, 'learning_rate': 0.2656891966998123, 'l2_leaf_reg': 1.7116499111496433, 'bagging_temperature': 1.4758971960884577, 'random_strength': 2.985115525193058, 'scale_pos_weight': 2.0779359776763604}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:13,351] Trial 41 finished with value: 0.6432160804020101 and parameters: {'iterations': 565, 'depth': 4, 'learning_rate': 0.1721301077006075, 'l2_leaf_reg': 2.83160215809792, 'bagging_temperature': 3.637840556586446, 'random_strength': 6.87949078255417, 'scale_pos_weight': 1.8465401309061407}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:14,011] Trial 42 finished with value: 0.6450116009280742 and parameters: {'iterations': 601, 'depth': 3, 'learning_rate': 0.1873947673207712, 'l2_leaf_reg': 2.9241337477745613, 'bagging_temperature': 0.5410478867023499, 'random_strength': 4.38220718225659, 'scale_pos_weight': 2.5091251981063993}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:14,887] Trial 43 finished with value: 0.615819209039548 and parameters: {'iterations': 417, 'depth': 8, 'learning_rate': 0.14429957167745827, 'l2_leaf_reg': 4.8392737681049915, 'bagging_temperature': 2.711097789512683, 'random_strength': 5.92265882420725, 'scale_pos_weight': 1.3691695937409998}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:15,624] Trial 44 finished with value: 0.6011904761904762 and parameters: {'iterations': 257, 'depth': 5, 'learning_rate': 0.13214088842014998, 'l2_leaf_reg': 3.7983089471489233, 'bagging_temperature': 9.017137114038606, 'random_strength': 3.4068724844647686, 'scale_pos_weight': 0.9845742929467024}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:16,268] Trial 45 finished with value: 0.6326530612244898 and parameters: {'iterations': 441, 'depth': 3, 'learning_rate': 0.15956718385883076, 'l2_leaf_reg': 1.2190497089881613, 'bagging_temperature': 9.961392696858303, 'random_strength': 1.5008057957568508, 'scale_pos_weight': 1.6731859792201773}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:16,685] Trial 46 finished with value: 0.6408602150537634 and parameters: {'iterations': 521, 'depth': 4, 'learning_rate': 0.22631566004547693, 'l2_leaf_reg': 2.314335815511889, 'bagging_temperature': 6.83793629210453, 'random_strength': 0.8982152866078933, 'scale_pos_weight': 2.995317188882245}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:17,141] Trial 47 finished with value: 0.6409638554216868 and parameters: {'iterations': 1088, 'depth': 5, 'learning_rate': 0.2057022661663653, 'l2_leaf_reg': 3.092103178861926, 'bagging_temperature': 3.1247693899178843, 'random_strength': 6.407551129815888, 'scale_pos_weight': 2.184177857925147}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:17,895] Trial 48 finished with value: 0.6584766584766585 and parameters: {'iterations': 358, 'depth': 4, 'learning_rate': 0.18355609929439096, 'l2_leaf_reg': 5.572178325603211, 'bagging_temperature': 4.3071585371784336, 'random_strength': 0.11056465464066467, 'scale_pos_weight': 1.9920623371540986}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:18,262] Trial 49 finished with value: 0.6437346437346437 and parameters: {'iterations': 347, 'depth': 4, 'learning_rate': 0.18887743106996938, 'l2_leaf_reg': 5.687321412774573, 'bagging_temperature': 4.428793787866885, 'random_strength': 0.32808847527417695, 'scale_pos_weight': 2.0653735761563037}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:18,990] Trial 50 finished with value: 0.628099173553719 and parameters: {'iterations': 294, 'depth': 3, 'learning_rate': 0.2226869278494954, 'l2_leaf_reg': 5.24994852932821, 'bagging_temperature': 4.043519600313412, 'random_strength': 0.9641490380311355, 'scale_pos_weight': 1.3401823058295026}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:19,660] Trial 51 finished with value: 0.6547085201793722 and parameters: {'iterations': 378, 'depth': 4, 'learning_rate': 0.1696460429753864, 'l2_leaf_reg': 2.503060249933448, 'bagging_temperature': 7.549522863576893, 'random_strength': 5.281917504777048, 'scale_pos_weight': 2.6471691484476336}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:20,229] Trial 52 finished with value: 0.6450116009280742 and parameters: {'iterations': 389, 'depth': 4, 'learning_rate': 0.16780861350964213, 'l2_leaf_reg': 1.9810614046145854, 'bagging_temperature': 7.649645739405719, 'random_strength': 5.5752229140595935, 'scale_pos_weight': 2.341301017635845}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:20,737] Trial 53 finished with value: 0.6425339366515838 and parameters: {'iterations': 236, 'depth': 4, 'learning_rate': 0.18400312953040848, 'l2_leaf_reg': 2.601429515841847, 'bagging_temperature': 5.503956367440649, 'random_strength': 0.710326183688903, 'scale_pos_weight': 2.6525390480845563}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:21,295] Trial 54 finished with value: 0.638961038961039 and parameters: {'iterations': 441, 'depth': 5, 'learning_rate': 0.19991176279415615, 'l2_leaf_reg': 3.813033676910158, 'bagging_temperature': 9.503297385927649, 'random_strength': 1.9378636940539498, 'scale_pos_weight': 1.639605821748374}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:21,754] Trial 55 finished with value: 0.6386138613861386 and parameters: {'iterations': 364, 'depth': 3, 'learning_rate': 0.15141710005493822, 'l2_leaf_reg': 4.343883162895597, 'bagging_temperature': 6.7902881301318265, 'random_strength': 1.2522852291462259, 'scale_pos_weight': 1.8777418875731746}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:22,222] Trial 56 finished with value: 0.6419753086419753 and parameters: {'iterations': 304, 'depth': 4, 'learning_rate': 0.13372199672997762, 'l2_leaf_reg': 8.781603364680292, 'bagging_temperature': 8.93185463300627, 'random_strength': 4.624199854607491, 'scale_pos_weight': 1.9697148768313462}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:22,666] Trial 57 finished with value: 0.64 and parameters: {'iterations': 251, 'depth': 5, 'learning_rate': 0.16665047616182005, 'l2_leaf_reg': 0.6781260935912936, 'bagging_temperature': 8.411410760283136, 'random_strength': 0.10963695703451659, 'scale_pos_weight': 2.374629206462573}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:23,475] Trial 58 finished with value: 0.6270270270270271 and parameters: {'iterations': 406, 'depth': 4, 'learning_rate': 0.12439202338136504, 'l2_leaf_reg': 1.6320378223132468, 'bagging_temperature': 9.388605670011863, 'random_strength': 5.453115975314287, 'scale_pos_weight': 1.5105725817372075}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:24,010] Trial 59 finished with value: 0.6394557823129252 and parameters: {'iterations': 507, 'depth': 3, 'learning_rate': 0.23798949481543785, 'l2_leaf_reg': 5.738755149293142, 'bagging_temperature': 7.690262579530174, 'random_strength': 3.6515760000374082, 'scale_pos_weight': 2.5922636940955415}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:24,611] Trial 60 finished with value: 0.6504424778761062 and parameters: {'iterations': 337, 'depth': 5, 'learning_rate': 0.18333374883741113, 'l2_leaf_reg': 4.817691246966608, 'bagging_temperature': 4.83156380145631, 'random_strength': 2.836919929248897, 'scale_pos_weight': 2.823388545588272}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:25,162] Trial 61 finished with value: 0.6355555555555555 and parameters: {'iterations': 341, 'depth': 5, 'learning_rate': 0.18121616729980658, 'l2_leaf_reg': 6.954464818534827, 'bagging_temperature': 4.977164994970984, 'random_strength': 2.8023545981973474, 'scale_pos_weight': 2.826307262140775}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:25,556] Trial 62 finished with value: 0.6536796536796536 and parameters: {'iterations': 270, 'depth': 4, 'learning_rate': 0.20747491346207278, 'l2_leaf_reg': 3.5995022410935844, 'bagging_temperature': 4.779823101675549, 'random_strength': 1.7359842198104225, 'scale_pos_weight': 2.9752327837960912}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:26,038] Trial 63 finished with value: 0.6496815286624203 and parameters: {'iterations': 269, 'depth': 4, 'learning_rate': 0.20642558788171173, 'l2_leaf_reg': 4.75893577253591, 'bagging_temperature': 5.717213284101122, 'random_strength': 1.7693429166194812, 'scale_pos_weight': 2.9698789203186315}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:26,416] Trial 64 finished with value: 0.642706131078224 and parameters: {'iterations': 374, 'depth': 4, 'learning_rate': 0.192140532498871, 'l2_leaf_reg': 4.162474760776417, 'bagging_temperature': 4.890122688357118, 'random_strength': 1.4432941072954548, 'scale_pos_weight': 3.177427786871454}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:26,955] Trial 65 finished with value: 0.6443514644351465 and parameters: {'iterations': 445, 'depth': 5, 'learning_rate': 0.2203723233399836, 'l2_leaf_reg': 3.624603320687771, 'bagging_temperature': 4.168691190595857, 'random_strength': 5.20412765295273, 'scale_pos_weight': 3.339161815778281}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:27,530] Trial 66 finished with value: 0.6460905349794238 and parameters: {'iterations': 313, 'depth': 4, 'learning_rate': 0.20376122186400528, 'l2_leaf_reg': 3.1302881942248235, 'bagging_temperature': 4.609680093134885, 'random_strength': 2.066649122832658, 'scale_pos_weight': 3.595428886408256}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:28,142] Trial 67 finished with value: 0.64 and parameters: {'iterations': 232, 'depth': 5, 'learning_rate': 0.02253111886758935, 'l2_leaf_reg': 2.429086620535303, 'bagging_temperature': 3.659354614293109, 'random_strength': 0.5957240035948721, 'scale_pos_weight': 2.7644787675519136}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:28,510] Trial 68 finished with value: 0.6477024070021882 and parameters: {'iterations': 741, 'depth': 6, 'learning_rate': 0.2136804179511349, 'l2_leaf_reg': 5.006129965182348, 'bagging_temperature': 2.1299794793713644, 'random_strength': 1.1296533717569335, 'scale_pos_weight': 2.904635226228809}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:29,223] Trial 69 finished with value: 0.6433566433566433 and parameters: {'iterations': 271, 'depth': 4, 'learning_rate': 0.1535362873098267, 'l2_leaf_reg': 5.533391930612694, 'bagging_temperature': 5.593550968497373, 'random_strength': 2.319519531364104, 'scale_pos_weight': 2.452358727651}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:29,669] Trial 70 finished with value: 0.6495726495726496 and parameters: {'iterations': 395, 'depth': 4, 'learning_rate': 0.19670378915803788, 'l2_leaf_reg': 1.9016115108848894, 'bagging_temperature': 4.6897816794598555, 'random_strength': 1.3423165219541902, 'scale_pos_weight': 3.0861700364956004}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:30,215] Trial 71 finished with value: 0.6451612903225806 and parameters: {'iterations': 267, 'depth': 4, 'learning_rate': 0.23167778310838594, 'l2_leaf_reg': 4.738554190077513, 'bagging_temperature': 5.431119416107984, 'random_strength': 1.8460492051490927, 'scale_pos_weight': 2.9571611516981235}. Best is trial 32 with value: 0.6587677725118484.\n",
      "[I 2025-11-27 17:10:30,707] Trial 72 finished with value: 0.6605922551252847 and parameters: {'iterations': 357, 'depth': 4, 'learning_rate': 0.25046247180450054, 'l2_leaf_reg': 4.404775801805672, 'bagging_temperature': 5.938702314381068, 'random_strength': 1.711236633982345, 'scale_pos_weight': 2.6460366590707878}. Best is trial 72 with value: 0.6605922551252847.\n",
      "[I 2025-11-27 17:10:31,105] Trial 73 finished with value: 0.6538461538461539 and parameters: {'iterations': 350, 'depth': 4, 'learning_rate': 0.24989946962412235, 'l2_leaf_reg': 6.037205195657387, 'bagging_temperature': 5.8282954886986, 'random_strength': 0.7903580517254991, 'scale_pos_weight': 2.189046163947803}. Best is trial 72 with value: 0.6605922551252847.\n",
      "[I 2025-11-27 17:10:31,465] Trial 74 finished with value: 0.6522781774580336 and parameters: {'iterations': 364, 'depth': 4, 'learning_rate': 0.2547556680342643, 'l2_leaf_reg': 6.13650847123087, 'bagging_temperature': 6.456842375658228, 'random_strength': 0.7462265501002381, 'scale_pos_weight': 2.222198818376593}. Best is trial 72 with value: 0.6605922551252847.\n",
      "[I 2025-11-27 17:10:31,805] Trial 75 finished with value: 0.6527777777777778 and parameters: {'iterations': 468, 'depth': 4, 'learning_rate': 0.2563726564852425, 'l2_leaf_reg': 6.8465883731191886, 'bagging_temperature': 6.42583951714897, 'random_strength': 0.474234248359546, 'scale_pos_weight': 2.581789965379737}. Best is trial 72 with value: 0.6605922551252847.\n",
      "[I 2025-11-27 17:10:32,216] Trial 76 finished with value: 0.6532438478747203 and parameters: {'iterations': 417, 'depth': 3, 'learning_rate': 0.2795753702909777, 'l2_leaf_reg': 6.659118677403834, 'bagging_temperature': 5.822272563173432, 'random_strength': 0.3473145200066564, 'scale_pos_weight': 2.6338898214520112}. Best is trial 72 with value: 0.6605922551252847.\n",
      "[I 2025-11-27 17:10:32,795] Trial 77 finished with value: 0.6607929515418502 and parameters: {'iterations': 416, 'depth': 3, 'learning_rate': 0.29699044830443816, 'l2_leaf_reg': 6.678616401351957, 'bagging_temperature': 5.873498452213724, 'random_strength': 8.776058577368062, 'scale_pos_weight': 2.6789052335710384}. Best is trial 77 with value: 0.6607929515418502.\n",
      "[I 2025-11-27 17:10:33,404] Trial 78 finished with value: 0.6547085201793722 and parameters: {'iterations': 416, 'depth': 3, 'learning_rate': 0.29211783592156193, 'l2_leaf_reg': 7.965384369955439, 'bagging_temperature': 5.839771403185063, 'random_strength': 8.976358330276929, 'scale_pos_weight': 2.6994954419099226}. Best is trial 77 with value: 0.6607929515418502.\n",
      "[I 2025-11-27 17:10:33,815] Trial 79 finished with value: 0.6513761467889908 and parameters: {'iterations': 552, 'depth': 3, 'learning_rate': 0.29359125453718854, 'l2_leaf_reg': 8.163578567175538, 'bagging_temperature': 7.183103188891275, 'random_strength': 8.461862806635533, 'scale_pos_weight': 2.445529792893642}. Best is trial 77 with value: 0.6607929515418502.\n",
      "[I 2025-11-27 17:10:34,236] Trial 80 finished with value: 0.6140035906642729 and parameters: {'iterations': 317, 'depth': 3, 'learning_rate': 0.28629694282932394, 'l2_leaf_reg': 8.735422775690093, 'bagging_temperature': 5.227979009444806, 'random_strength': 9.15685774196219, 'scale_pos_weight': 4.8265478869280365}. Best is trial 77 with value: 0.6607929515418502.\n",
      "[I 2025-11-27 17:10:34,636] Trial 81 finished with value: 0.6592920353982301 and parameters: {'iterations': 424, 'depth': 3, 'learning_rate': 0.2803594648434283, 'l2_leaf_reg': 7.907372853723567, 'bagging_temperature': 5.797420771072178, 'random_strength': 9.794908234464001, 'scale_pos_weight': 2.676257497388619}. Best is trial 77 with value: 0.6607929515418502.\n",
      "[I 2025-11-27 17:10:35,038] Trial 82 finished with value: 0.6666666666666666 and parameters: {'iterations': 385, 'depth': 3, 'learning_rate': 0.2729136260896351, 'l2_leaf_reg': 7.931611066203784, 'bagging_temperature': 5.9307019430354195, 'random_strength': 9.994190206415958, 'scale_pos_weight': 2.7190976516167833}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:35,406] Trial 83 finished with value: 0.6636971046770601 and parameters: {'iterations': 453, 'depth': 3, 'learning_rate': 0.2764834818718929, 'l2_leaf_reg': 8.382680093263314, 'bagging_temperature': 6.00560730081325, 'random_strength': 9.67998907713761, 'scale_pos_weight': 2.6762584165961956}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:36,199] Trial 84 finished with value: 0.6607142857142857 and parameters: {'iterations': 454, 'depth': 3, 'learning_rate': 0.27007362304865856, 'l2_leaf_reg': 7.792284880620793, 'bagging_temperature': 6.099287845221748, 'random_strength': 9.98342895480315, 'scale_pos_weight': 2.7006987992828364}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:36,650] Trial 85 finished with value: 0.6523605150214592 and parameters: {'iterations': 458, 'depth': 3, 'learning_rate': 0.27357106812710524, 'l2_leaf_reg': 8.05535179526386, 'bagging_temperature': 6.704989830581124, 'random_strength': 9.918006773710987, 'scale_pos_weight': 2.7435520719401554}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:37,079] Trial 86 finished with value: 0.6554621848739496 and parameters: {'iterations': 390, 'depth': 3, 'learning_rate': 0.29999265595877384, 'l2_leaf_reg': 7.662417360516092, 'bagging_temperature': 6.040307551415527, 'random_strength': 9.617407165842094, 'scale_pos_weight': 3.157007279022252}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:37,496] Trial 87 finished with value: 0.6450304259634888 and parameters: {'iterations': 531, 'depth': 3, 'learning_rate': 0.2664212434170431, 'l2_leaf_reg': 8.99725829853601, 'bagging_temperature': 6.150646348826078, 'random_strength': 9.579278886403175, 'scale_pos_weight': 3.50924893445428}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:37,930] Trial 88 finished with value: 0.6496815286624203 and parameters: {'iterations': 507, 'depth': 3, 'learning_rate': 0.2987529304255013, 'l2_leaf_reg': 7.306474812237466, 'bagging_temperature': 6.568970437560581, 'random_strength': 9.40982927243348, 'scale_pos_weight': 3.0877896276415053}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:38,366] Trial 89 finished with value: 0.6597077244258872 and parameters: {'iterations': 496, 'depth': 3, 'learning_rate': 0.2810275219154406, 'l2_leaf_reg': 7.7400962862740865, 'bagging_temperature': 5.321481509087645, 'random_strength': 8.546470450440673, 'scale_pos_weight': 3.2366775077236}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:38,729] Trial 90 finished with value: 0.6417322834645669 and parameters: {'iterations': 602, 'depth': 3, 'learning_rate': 0.2799634940825644, 'l2_leaf_reg': 9.458881166291134, 'bagging_temperature': 5.122182525331219, 'random_strength': 8.569514459486161, 'scale_pos_weight': 3.814301629715128}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:39,104] Trial 91 finished with value: 0.6471816283924844 and parameters: {'iterations': 492, 'depth': 3, 'learning_rate': 0.28543993475146867, 'l2_leaf_reg': 8.393927015656628, 'bagging_temperature': 5.989250432259388, 'random_strength': 9.72194513214145, 'scale_pos_weight': 3.2087390095975445}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:39,563] Trial 92 finished with value: 0.6556016597510373 and parameters: {'iterations': 428, 'depth': 3, 'learning_rate': 0.26317923011714306, 'l2_leaf_reg': 7.681321542653442, 'bagging_temperature': 5.447044893373787, 'random_strength': 8.757912242356209, 'scale_pos_weight': 3.2916918064168654}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:40,034] Trial 93 finished with value: 0.6403326403326404 and parameters: {'iterations': 456, 'depth': 3, 'learning_rate': 0.263299591247421, 'l2_leaf_reg': 7.543789284205251, 'bagging_temperature': 6.276758128345346, 'random_strength': 8.573335294936228, 'scale_pos_weight': 3.3056454693519246}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:40,582] Trial 94 finished with value: 0.6636971046770601 and parameters: {'iterations': 432, 'depth': 3, 'learning_rate': 0.27246210257921333, 'l2_leaf_reg': 8.451059490788628, 'bagging_temperature': 5.412361250592674, 'random_strength': 8.930355245764089, 'scale_pos_weight': 2.5458705706523714}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:40,955] Trial 95 finished with value: 0.6496519721577726 and parameters: {'iterations': 484, 'depth': 3, 'learning_rate': 0.27544878348573576, 'l2_leaf_reg': 8.367582610801445, 'bagging_temperature': 7.02389886329284, 'random_strength': 8.219390898218808, 'scale_pos_weight': 2.3246780425151328}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:41,516] Trial 96 finished with value: 0.6577181208053692 and parameters: {'iterations': 532, 'depth': 3, 'learning_rate': 0.28889214086502957, 'l2_leaf_reg': 7.086897471463282, 'bagging_temperature': 5.2100843447427305, 'random_strength': 9.258905484307965, 'scale_pos_weight': 2.526749424605396}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:42,092] Trial 97 finished with value: 0.6453089244851259 and parameters: {'iterations': 438, 'depth': 3, 'learning_rate': 0.28184254412440735, 'l2_leaf_reg': 9.07729528077174, 'bagging_temperature': 4.234884209173097, 'random_strength': 9.978467575282833, 'scale_pos_weight': 2.400146374176512}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:42,706] Trial 98 finished with value: 0.6571428571428571 and parameters: {'iterations': 576, 'depth': 3, 'learning_rate': 0.24583010670593541, 'l2_leaf_reg': 7.845024593339214, 'bagging_temperature': 4.40097786545986, 'random_strength': 8.884464553756985, 'scale_pos_weight': 2.0933196915256373}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:43,674] Trial 99 finished with value: 0.6331877729257642 and parameters: {'iterations': 389, 'depth': 9, 'learning_rate': 0.2697136899197808, 'l2_leaf_reg': 8.35576353382214, 'bagging_temperature': 5.30302841580855, 'random_strength': 7.323863644385024, 'scale_pos_weight': 2.8770766447767078}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:44,183] Trial 100 finished with value: 0.6435185185185185 and parameters: {'iterations': 355, 'depth': 3, 'learning_rate': 0.259114617166296, 'l2_leaf_reg': 8.592091555827972, 'bagging_temperature': 5.693446594025172, 'random_strength': 9.386429104482106, 'scale_pos_weight': 2.2843017743334326}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:44,673] Trial 101 finished with value: 0.654627539503386 and parameters: {'iterations': 633, 'depth': 3, 'learning_rate': 0.2908704226451908, 'l2_leaf_reg': 7.3787486064810786, 'bagging_temperature': 5.440005813572901, 'random_strength': 9.306214304968684, 'scale_pos_weight': 2.4945929936529976}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:45,173] Trial 102 finished with value: 0.6565217391304348 and parameters: {'iterations': 409, 'depth': 3, 'learning_rate': 0.27317928203443315, 'l2_leaf_reg': 6.961405119219262, 'bagging_temperature': 5.141179947371061, 'random_strength': 9.162672829358876, 'scale_pos_weight': 2.755208100039896}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:45,701] Trial 103 finished with value: 0.6486486486486487 and parameters: {'iterations': 519, 'depth': 3, 'learning_rate': 0.28360130912769915, 'l2_leaf_reg': 7.209821922496477, 'bagging_temperature': 5.942550945281177, 'random_strength': 9.823182585531779, 'scale_pos_weight': 2.5755432829667493}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:46,180] Trial 104 finished with value: 0.6550218340611353 and parameters: {'iterations': 1184, 'depth': 3, 'learning_rate': 0.28945870967208776, 'l2_leaf_reg': 7.852825423622845, 'bagging_temperature': 5.028650456335524, 'random_strength': 8.195363721484052, 'scale_pos_weight': 2.6940241701974292}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:46,617] Trial 105 finished with value: 0.6589327146171694 and parameters: {'iterations': 468, 'depth': 3, 'learning_rate': 0.267870154760274, 'l2_leaf_reg': 8.166579716008599, 'bagging_temperature': 3.904733830691788, 'random_strength': 9.531531035138022, 'scale_pos_weight': 2.5199710414716456}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:47,170] Trial 106 finished with value: 0.6510638297872341 and parameters: {'iterations': 457, 'depth': 3, 'learning_rate': 0.2424809992067932, 'l2_leaf_reg': 6.386988726497294, 'bagging_temperature': 3.905755752607906, 'random_strength': 9.668070923468843, 'scale_pos_weight': 3.0410108760662746}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:47,613] Trial 107 finished with value: 0.6535087719298246 and parameters: {'iterations': 429, 'depth': 3, 'learning_rate': 0.2702501550495104, 'l2_leaf_reg': 8.547595044331496, 'bagging_temperature': 3.311569009582021, 'random_strength': 9.444839545768557, 'scale_pos_weight': 2.88611187730828}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:48,363] Trial 108 finished with value: 0.6575342465753424 and parameters: {'iterations': 495, 'depth': 3, 'learning_rate': 0.2776279433932237, 'l2_leaf_reg': 8.244913573967223, 'bagging_temperature': 6.303512511641432, 'random_strength': 8.943456250059272, 'scale_pos_weight': 2.393448645843825}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:48,978] Trial 109 finished with value: 0.6487695749440716 and parameters: {'iterations': 378, 'depth': 3, 'learning_rate': 0.25109866274380793, 'l2_leaf_reg': 9.302320105906222, 'bagging_temperature': 3.711046082658803, 'random_strength': 9.951050720740021, 'scale_pos_weight': 2.5456461699198174}. Best is trial 82 with value: 0.6666666666666666.\n",
      "[I 2025-11-27 17:10:49,453] Trial 110 finished with value: 0.6695842450765864 and parameters: {'iterations': 993, 'depth': 3, 'learning_rate': 0.2356797718799401, 'l2_leaf_reg': 9.972120267755898, 'bagging_temperature': 6.622206153811139, 'random_strength': 8.171993999319865, 'scale_pos_weight': 2.8014314699721883}. Best is trial 110 with value: 0.6695842450765864.\n",
      "[I 2025-11-27 17:10:50,008] Trial 111 finished with value: 0.6534216335540839 and parameters: {'iterations': 402, 'depth': 3, 'learning_rate': 0.2603630295599541, 'l2_leaf_reg': 9.078024621207575, 'bagging_temperature': 6.6237507589631965, 'random_strength': 8.365880348479285, 'scale_pos_weight': 2.7674103057903836}. Best is trial 110 with value: 0.6695842450765864.\n",
      "[I 2025-11-27 17:10:50,640] Trial 112 finished with value: 0.6505494505494506 and parameters: {'iterations': 1060, 'depth': 3, 'learning_rate': 0.2349377981999563, 'l2_leaf_reg': 7.506577686085661, 'bagging_temperature': 5.6485745275740005, 'random_strength': 8.0121174128655, 'scale_pos_weight': 2.6432642814371925}. Best is trial 110 with value: 0.6695842450765864.\n",
      "[I 2025-11-27 17:10:51,219] Trial 113 finished with value: 0.6608695652173913 and parameters: {'iterations': 954, 'depth': 3, 'learning_rate': 0.26714678056486346, 'l2_leaf_reg': 9.81128456092968, 'bagging_temperature': 6.8709383594490605, 'random_strength': 8.681323557246962, 'scale_pos_weight': 2.8062792816845663}. Best is trial 110 with value: 0.6695842450765864.\n",
      "[I 2025-11-27 17:10:51,787] Trial 114 finished with value: 0.6520787746170679 and parameters: {'iterations': 914, 'depth': 3, 'learning_rate': 0.26644344639855244, 'l2_leaf_reg': 9.798717961499309, 'bagging_temperature': 7.019673547303987, 'random_strength': 7.53203812023574, 'scale_pos_weight': 2.8254455871788493}. Best is trial 110 with value: 0.6695842450765864.\n",
      "[I 2025-11-27 17:10:52,308] Trial 115 finished with value: 0.6437768240343348 and parameters: {'iterations': 981, 'depth': 3, 'learning_rate': 0.24290902675849518, 'l2_leaf_reg': 9.608465800472521, 'bagging_temperature': 7.3739169357162115, 'random_strength': 8.801329071107206, 'scale_pos_weight': 2.923051275867057}. Best is trial 110 with value: 0.6695842450765864.\n",
      "[I 2025-11-27 17:10:52,928] Trial 116 finished with value: 0.6564551422319475 and parameters: {'iterations': 982, 'depth': 3, 'learning_rate': 0.25594109787973796, 'l2_leaf_reg': 9.907516081812739, 'bagging_temperature': 6.187601164644438, 'random_strength': 9.039185785592487, 'scale_pos_weight': 2.7141437844997194}. Best is trial 110 with value: 0.6695842450765864.\n",
      "[I 2025-11-27 17:10:53,308] Trial 117 finished with value: 0.642706131078224 and parameters: {'iterations': 468, 'depth': 3, 'learning_rate': 0.27571624796994393, 'l2_leaf_reg': 8.895966596271544, 'bagging_temperature': 6.4119169641965055, 'random_strength': 9.510781163039555, 'scale_pos_weight': 3.0674828117313706}. Best is trial 110 with value: 0.6695842450765864.\n",
      "[I 2025-11-27 17:10:54,085] Trial 118 finished with value: 0.6455981941309256 and parameters: {'iterations': 1009, 'depth': 3, 'learning_rate': 0.24714336571741005, 'l2_leaf_reg': 9.26686347686468, 'bagging_temperature': 6.115976489340489, 'random_strength': 7.987308483815672, 'scale_pos_weight': 2.4605756355687594}. Best is trial 110 with value: 0.6695842450765864.\n",
      "[I 2025-11-27 17:10:54,759] Trial 119 finished with value: 0.6515837104072398 and parameters: {'iterations': 949, 'depth': 7, 'learning_rate': 0.26838295066342743, 'l2_leaf_reg': 7.983901556962095, 'bagging_temperature': 6.855527102755527, 'random_strength': 9.777740500226823, 'scale_pos_weight': 2.7860872458539774}. Best is trial 110 with value: 0.6695842450765864.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Best F1: 0.6695842450765864\n",
      "ðŸ”¥ Best Params:\n",
      " {'iterations': 993, 'depth': 3, 'learning_rate': 0.2356797718799401, 'l2_leaf_reg': 9.972120267755898, 'bagging_temperature': 6.622206153811139, 'random_strength': 8.171993999319865, 'scale_pos_weight': 2.8014314699721883}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(cat_objective, n_trials=120, show_progress_bar=False)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Best F1:\", study.best_value)\n",
    "print(\"ðŸ”¥ Best Params:\\n\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e02ad743",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_best_params = study.best_params\n",
    "cat_best_params[\"loss_function\"] = \"Logloss\"\n",
    "cat_best_params[\"eval_metric\"] = \"F1\"\n",
    "cat_best_params[\"verbose\"] = False\n",
    "cat_best_params[\"use_best_model\"] = True\n",
    "cat_best_params[\"random_seed\"] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c78165b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       796\n",
      "           1       0.60      0.75      0.67       204\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.77      0.81      0.79      1000\n",
      "weighted avg       0.87      0.85      0.85      1000\n",
      "\n",
      "F1: 0.6695842450765864\n",
      "===================================================\n",
      "\n",
      "Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      7167\n",
      "           1       0.61      0.71      0.66      1833\n",
      "\n",
      "    accuracy                           0.85      9000\n",
      "   macro avg       0.77      0.80      0.78      9000\n",
      "weighted avg       0.86      0.85      0.85      9000\n",
      "\n",
      "F1: 0.6582661290322581\n"
     ]
    }
   ],
   "source": [
    "tunned_cat_model = CatBoostClassifier(**cat_best_params)\n",
    "\n",
    "train_pool = Pool(X_train_processed, y_train)\n",
    "valid_pool = Pool(X_test_processed, y_test)\n",
    "\n",
    "tunned_cat_model.fit(\n",
    "    train_pool,\n",
    "    eval_set=valid_pool,\n",
    "    early_stopping_rounds=80,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_test_pred_cat = tunned_cat_model.predict(X_test_processed)\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_test_pred_cat))\n",
    "print(\"F1:\", f1_score(y_test, y_test_pred_cat))\n",
    "print('===================================================')\n",
    "y_train_pred_cat = tunned_cat_model.predict(X_train_processed)\n",
    "print(\"\\nClassification Report (Train):\")\n",
    "print(classification_report(y_train, y_train_pred_cat))\n",
    "print(\"F1:\", f1_score(y_train, y_train_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e84c6936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP feature importance\n",
    "explainer = shap.Explainer(tunned_cat_model, X_train_processed)\n",
    "shap_values = explainer(X_train_processed)\n",
    "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "# Create DF\n",
    "shap_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'SHAP_Value': mean_abs_shap\n",
    "}).sort_values(by='SHAP_Value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fb546d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Feature</th>\n",
       "      <th>SHAP_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>num__Age</td>\n",
       "      <td>0.695470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>ready__NumOfProducts</td>\n",
       "      <td>0.631179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>ready__IsActiveMember</td>\n",
       "      <td>0.384348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>cat__Gender_Male</td>\n",
       "      <td>0.239029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>cat__Geography_Germany</td>\n",
       "      <td>0.183934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>num__Balance</td>\n",
       "      <td>0.176496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>num__AgeProduct</td>\n",
       "      <td>0.145871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>num__LogBalanceSalaryRatio</td>\n",
       "      <td>0.127245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>ready__ActivityScore</td>\n",
       "      <td>0.079072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>num__CreditScore</td>\n",
       "      <td>0.061759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>num__EstimatedSalary</td>\n",
       "      <td>0.053703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>cat__AgeGroup_Senior</td>\n",
       "      <td>0.047130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>num__CustomerValue</td>\n",
       "      <td>0.038902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>num__CLV</td>\n",
       "      <td>0.036915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>num__Tenure</td>\n",
       "      <td>0.033412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22</td>\n",
       "      <td>ready__HighBalance</td>\n",
       "      <td>0.020718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>cat__Geography_Spain</td>\n",
       "      <td>0.017502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>ready__HasCrCard</td>\n",
       "      <td>0.011578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14</td>\n",
       "      <td>cat__AgeGroup_Young</td>\n",
       "      <td>0.011145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17</td>\n",
       "      <td>cat__CreditTier_superprime</td>\n",
       "      <td>0.008032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16</td>\n",
       "      <td>cat__CreditTier_subprime</td>\n",
       "      <td>0.007032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12</td>\n",
       "      <td>cat__AgeGroup_Elderly</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15</td>\n",
       "      <td>cat__CreditTier_prime</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19</td>\n",
       "      <td>ready__IsZeroBalance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                     Feature  SHAP_Value\n",
       "0       2                    num__Age    0.695470\n",
       "1      20        ready__NumOfProducts    0.631179\n",
       "2      21       ready__IsActiveMember    0.384348\n",
       "3      11            cat__Gender_Male    0.239029\n",
       "4       9      cat__Geography_Germany    0.183934\n",
       "5       3                num__Balance    0.176496\n",
       "6       7             num__AgeProduct    0.145871\n",
       "7       5  num__LogBalanceSalaryRatio    0.127245\n",
       "8      23        ready__ActivityScore    0.079072\n",
       "9       0            num__CreditScore    0.061759\n",
       "10      4        num__EstimatedSalary    0.053703\n",
       "11     13        cat__AgeGroup_Senior    0.047130\n",
       "12      6          num__CustomerValue    0.038902\n",
       "13      8                    num__CLV    0.036915\n",
       "14      1                 num__Tenure    0.033412\n",
       "15     22          ready__HighBalance    0.020718\n",
       "16     10        cat__Geography_Spain    0.017502\n",
       "17     18            ready__HasCrCard    0.011578\n",
       "18     14         cat__AgeGroup_Young    0.011145\n",
       "19     17  cat__CreditTier_superprime    0.008032\n",
       "20     16    cat__CreditTier_subprime    0.007032\n",
       "21     12       cat__AgeGroup_Elderly    0.000000\n",
       "22     15       cat__CreditTier_prime    0.000000\n",
       "23     19        ready__IsZeroBalance    0.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_df_cat = shap_df.reset_index()\n",
    "shap_df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc854de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = shap_df_cat['Feature'][:17].tolist()\n",
    "top_feature_indices = [feature_names.index(feat) for feat in top_features]\n",
    "X_train_top = X_train_processed[:, top_feature_indices]\n",
    "X_test_top = X_test_processed[:, top_feature_indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7c7c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90       796\n",
      "           1       0.59      0.71      0.64       204\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.75      0.79      0.77      1000\n",
      "weighted avg       0.85      0.84      0.84      1000\n",
      "\n",
      "F1: 0.6430155210643016\n",
      "\n",
      "Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      7167\n",
      "           1       0.60      0.70      0.65      1833\n",
      "\n",
      "    accuracy                           0.84      9000\n",
      "   macro avg       0.76      0.79      0.77      9000\n",
      "weighted avg       0.85      0.84      0.85      9000\n",
      "\n",
      "F1: 0.6452099572542117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_cat_model = CatBoostClassifier(**cat_best_params ,snapshot_file='cat_model.cbs')\n",
    "\n",
    "train_pool = Pool(X_train_top, y_train)\n",
    "valid_pool = Pool(X_test_top, y_test)\n",
    "\n",
    "final_cat_model.fit(\n",
    "    train_pool,\n",
    "    eval_set=valid_pool,\n",
    "    early_stopping_rounds=80,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_test_pred = final_cat_model.predict(X_test_top)\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_test_pred))\n",
    "\n",
    "y_train_pred = final_cat_model.predict(X_train_top)\n",
    "print(\"\\nClassification Report (Train):\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(\"F1:\", f1_score(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87240ad7",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6f14c",
   "metadata": {},
   "source": [
    "# save the final model and preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f916fc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models, checkpoints, and preprocessor saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import datetime\n",
    "\n",
    "# Base models directory\n",
    "BASE_MODEL_DIR = os.path.join(\"..\", \"models\")\n",
    "os.makedirs(BASE_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Timestamp for versioning\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb_dir = os.path.join(BASE_MODEL_DIR, f\"xgb_{timestamp}\")\n",
    "os.makedirs(xgb_dir, exist_ok=True)\n",
    "\n",
    "xgb_model_path = os.path.join(xgb_dir, \"model.pkl\")\n",
    "xgb_checkpoint_path = os.path.join(xgb_dir, \"checkpoint.json\")\n",
    "\n",
    "joblib.dump(final_xgb_model, xgb_model_path)\n",
    "final_xgb_model.save_model(xgb_checkpoint_path)\n",
    "\n",
    "# --- CatBoost ---\n",
    "cat_dir = os.path.join(BASE_MODEL_DIR, f\"catboost_{timestamp}\")\n",
    "os.makedirs(cat_dir, exist_ok=True)\n",
    "\n",
    "cat_model_path = os.path.join(cat_dir, \"model.pkl\")\n",
    "cat_checkpoint_path = os.path.join(cat_dir, \"checkpoint.cbs\")\n",
    "\n",
    "joblib.dump(final_cat_model, cat_model_path)\n",
    "final_cat_model.save_model(cat_checkpoint_path)\n",
    "\n",
    "# --- Preprocessor ---\n",
    "preprocessor_dir = os.path.join(BASE_MODEL_DIR, f\"preprocessor_{timestamp}\")\n",
    "os.makedirs(preprocessor_dir, exist_ok=True)\n",
    "\n",
    "preprocessor_path = os.path.join(preprocessor_dir, \"preprocessor.pkl\")\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "\n",
    "print(\"Models, checkpoints, and preprocessor saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2bf329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
